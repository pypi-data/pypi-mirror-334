Metadata-Version: 2.2
Name: docoreai
Version: 0.1.4
Summary: DoCoreAI is an intelligence profiler that optimizes prompts
Home-page: https://github.com/SajiJohnMiranda/DoCoreAI
Author: Saji John
Author-email: sajijohnmiranda@gmail.com
Project-URL: Documentation, https://your-docs-url.com
Project-URL: Blog Post, https://mobilights.medium.com/intelligent-prompt-optimization-bac89b64fa84
Project-URL: Source Code, https://github.com/SajiJohnMiranda/DoCoreAI
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Requires-Python: >=3.7
Description-Content-Type: text/markdown
License-File: LICENSE.md
Requires-Dist: uvicorn
Requires-Dist: pydantic
Requires-Dist: python-dotenv
Requires-Dist: openai
Requires-Dist: langchain
Requires-Dist: groq
Dynamic: author
Dynamic: author-email
Dynamic: classifier
Dynamic: description
Dynamic: description-content-type
Dynamic: home-page
Dynamic: project-url
Dynamic: requires-dist
Dynamic: requires-python
Dynamic: summary

# ğŸŒŸ DoCoreAI â€“ The Future of Smart AI Interactions  

**ğŸš€ Optimize LLM Responses | ğŸ› ï¸ Fine-Tune AI Intelligence | âš¡ Supercharge Prompting**  

---

## ğŸ”¥ What is DoCoreAI?  
DoCoreAI is an AI **intelligence profiler that optimizes prompts dynamically** based on predefined intelligence parameters. Instead of relying on generic LLM prompts, DoCoreAI customizes intelligence properties (such as reasoning, creativity, and precision) to ensure AI agents generate responses that perfectly align with their roles.

Its an **open-source powerhouse** designed to make **Large Language Models (LLMs) smarter, sharper, and more efficient**. It acts as a **plug-and-play optimizer** that dynamically enhances AI reasoning, problem-solving, and decision-making, giving developers total control over AI intelligence. 

Whether you're building an AI agent, chatbot, a virtual assistant, or a SaaS application, **DoCoreAI fine-tunes AI prompts in real time**, ensuring **clear, precise, and highly contextual responses**.  

---

## ğŸŒ Why DoCoreAI?  
### âœ… **Key Benefits**
- **ğŸ§  Smarter AI** â€“ Enhances reasoning, problem-solving, and adaptability.
- **âš¡ Best Responses** â€“ Intelligent prompts mean more accurate answers.
- **ğŸ”§ Full Control** â€“ Developers can fine-tune intelligence parameters like depth, creativity, and accuracy.
- **ğŸ”Œ Easy API Integration** â€“ Works seamlessly with OpenAI, Cohere, Mistral, and other LLMs.
- **ğŸ› ï¸ Open-Source & Extensible** â€“ Customize it for your specific use case.

  ğŸš¨Lets see some Problems:

  - Generic LLM prompts donâ€™t tell AI agents how smart to be for a task.

  - LLMs respond the same way to different tasks, often lacking role-specific intelligence.

  - A customer support AI should be empathetic and clear, while a data analyst AI should be logical and precise.

  - Generic prompts fail to define the intelligence level needed to perform a task efficiently when some tasks need high reasoning, low creativity, while others need high creativity, low precision..

  - Saves Developer's Time from Trial & Error - Tweaking the Prompt and Temperature. (Here, the right temperature gets set automatically based on the prompt content, role & intelligent parameter values)

  The Solution:

  DoCoreAI solves this by intelligently adjusting skill parameters based on context, so LLMs generate perfect responses for each role, ensuring:
  - Better response accuracy
  - Improved AI agent adaptability
  - Optimized decision-making and creativity when needed
  - Temperature get dynamically assigned

---

## ğŸ’¡ How Does It Work?  

DoCoreAI follows a structured process to enhance AI prompts:

1ï¸âƒ£ AI Role Detection â€“ Identifies the AI agentâ€™s role and task.  
2ï¸âƒ£ Intelligence Mapping â€“ Assigns reasoning, creativity, precision, and temperature values.  
3ï¸âƒ£ Prompt Optimization â€“ Fine-tunes the input prompt using optimized intelligence properties.  
4ï¸âƒ£ LLM Execution â€“ Sends the enhanced prompt to OpenAI, Groq, or other supported models.

ğŸ’¡ Example:  
**Before** DoCoreAI: "Summarize this report."  
**After** DoCoreAI: "Summarize this report with high precision (0.9), low creativity (0.2), and deep reasoning (0.8)."

### **ğŸ”— Step-by-Step Workflow:**
1ï¸âƒ£ **User Query â†’** A user submits a question/query to your application.  
2ï¸âƒ£ **DoCoreAI Enhances Prompt â†’** The system analyzes the query or prompt and generates an optimized prompt with **dynamic intelligence parameters**. The required intelligence range  for each these parameters (like **Reasoning** - Determines logical depth, **Creativity** - Adjusts randomness , **Precision** - Controls specificity)  are inferred from the query automatically. 

3ï¸âƒ£ **Send to LLM â†’** The refined prompt is sent to your preferred LLM (OpenAI, Anthropic, Cohere, etc.).  
4ï¸âƒ£ **LLM Response â†’** The model returns a highly optimized answer.  
5ï¸âƒ£ **Final Output â†’** Your application displays the AIâ€™s enhanced response to the user.  

ğŸ‘‰ **End Result?** More accurate, contextually rich, and intelligent AI responses that **feel human-like and insightful**.  

---

## ğŸ’¡ How DoCoreAI Helps AI Agents

DoCoreAI ensures that AI agents perform at their best by customizing intelligence settings per task. Hereâ€™s how:  

ğŸ“ Support Agent AI â†’ Needs high empathy, clarity, and logical reasoning.  
ğŸ“Š Data Analyst AI â†’ Requires high precision and deep analytical reasoning.  
ğŸ¨ Creative Writing AI â†’ Boosts creativity for idea generation and storytelling.  

This adaptive approach ensures that LLMs deliver role-specific, optimized responses every time.

---

## ğŸš€ Use Cases
DoCoreAI is highly versatile and can be integrated across various domains:

ğŸ”¹ Customer Support AI: Ensures friendly, concise, and empathetic interactions.  
ğŸ”¹ Business Analytics AI: Generates precise reports with accurate insights.  
ğŸ”¹ Medical AI Assistants: Maintains high reasoning while reducing creativity for factual correctness.  
ğŸ”¹ Content Creation AI: Enhances creativity while keeping precision at a balanced level.  
ğŸ”¹ Legal & Compliance AI: Ensures responses are strictly factual and highly precise.  

### ğŸ¢ **For Businesses & Startups:**
- **ğŸ¤– AI Agents, Chatbots & Virtual Assistants** â€“ Make AI interactions **more natural and helpful**.
- **ğŸ“ AI Customer Support** â€“ Improve support accuracy, reducing agent workload.
- **ğŸ“Š Data & Market Analysis** â€“ Extract **meaningful insights from unstructured data**.
- **ğŸ¨ Creative AI** â€“  Enhances storytelling, content generation, and brainstorming.

### ğŸ› ï¸ **For Developers & Engineers:**
- **âš™ï¸ Fine-Tuning Custom LLMs** â€“ Boost reasoning, logic, and adaptability.
- **ğŸ“ AI-Powered Content Generation** â€“ Enhance blogs, marketing copy, and technical writing.
- **ğŸ§ª Research & Experimentation** â€“ Test and build **next-gen AI applications**.  

### ğŸ’ **Generalized solution for All**
- **âš™ï¸ Easily Works across all domains and user roles, allowing fine-tuning for different applications
  
---

## ğŸ¯ Getting Started
### **ğŸ“Œ Installation**
You can install `docoreai` from PyPI using pip: and Quick test [Sample Code](./blob/main/tests/Quick%20Test/test.py)

```bash
pip install docoreai
```
OR

1ï¸âƒ£ Clone the repo:
```bash
 git clone https://github.com/SajiJohnMiranda/DoCoreAI.git
```
2ï¸âƒ£ Install dependencies:
```bash
pip install -r requirements.txt
```
3ï¸âƒ£ Run DoCoreAI:
```bash
uvicorn api.main:app
```
4ï¸âƒ£ Start using the API:
```bash
Browser POST "http://127.0.0.1:8000/docs" Select /intelligence-profiler-demo 
```

ğŸ‰ **You're all set to build smarter AI applications!**  

---

## ğŸ”— Integrations & Compatibility
DoCoreAI is designed to work seamlessly with major AI platforms:
- Works with **OpenAI GPT, Claude, LLaMA, Falcon, Cohere, and more.**
- Supports **LangChain, FastAPI, Flask, and Django.**
- Easy to extend via **plugin-based architecture.**

---

## ğŸ“ˆ Why Developers Should Use DoCoreAI

ğŸ”¹ Smarter AI, Better Results  
-Ensures AI models understand the intelligence scope required for each task.  
-Enhances prompt efficiency, reducing trial and error in prompt engineering.

ğŸ”¹ Saves Time & Effort  
-No need for manual prompt tuningâ€”DoCoreAI does it for you.  
-Works out of the box with OpenAI and Groq models.

ğŸ”¹ Ideal for SaaS & AI-driven Applications  
-Perfect for chatbots, AI assistants, automation, and enterprise AI solutions.  
-DoCoreAI transforms AI interactions by making prompts truly intelligent.

---

## ğŸŒŸ Join the Community:  
Letâ€™s build the future of AI-powered intelligence tuning together! ğŸš€  
ğŸ¤ **Contribute:** Open issues, create pull requests, and help improve DoCoreAI!  
ğŸ“¢ **Discuss & Collaborate:** Join our **Discord & GitHub Discussions**.  
ğŸŒŸ **Star the Repo!** If you find this useful, donâ€™t forget to star â­ it on GitHub!  

ğŸ‘‰ [GitHub Repo](https://github.com/SajiJohnMiranda/DoCoreAI) | [Docs (Coming Soon)]  

---

## Recommended LLMs for Intelligence Optimization
DoCoreAI is designed to refine and optimize user prompts by dynamically adjusting intelligence parameters such as reasoning, creativity, and precision. To achieve the best results, we recommend using ChatGPT (GPT-4-turbo) for this task.
While DoCoreAI is compatible with other LLMs (e.g., LLaMA 3, Claude etc), results may vary depending on the modelâ€™s capabilities. Developers are encouraged to experiment and contribute insights on different LLM integrations.

**Future Support for Fine-Tuned Models:**  
We recognize the growing demand for fine-tuned open-source models tailored for specific applications. In future updates, we aim to explore Integration with fine-tuned LLaMA/Custom GPT models, Support for locally deployed models (via Ollama, vLLM, etc.) & Customization of intelligence parameters based on domain-specific data.

Our vision is to make DoCoreAI adaptable to both proprietary and open-source AI models, ensuring flexibility for all developers. Contributions and suggestions are welcome!

---

## Finally Why DoCoreAI?

- It **quantifies prompt intelligence** instead of relying on trial-and-error prompts.
- AI **responds efficiently** when guided by reasoning, creativity, and precision metrics.

---

## How to set it up

After installing `docoreai`, create a `.env` file in the root directory with the following content:

```ini
# .env file
OPENAI_API_KEY="your-openai-api-key"
GROQ_API_KEY="your-groq-api-key"
MODEL_PROVIDER="openai"  # Choose 'openai' or 'groq'
MODEL_NAME='gpt-3.5-turbo' # Choose model  gpt-3.5-turbo, gemma2-9b-it etc
```
---

## âš–ï¸ License
Licensed under [MIT License](./LICENSE.md). Use freely, contribute, and enhance AI for everyone!    

---

ğŸ’¡ **Letâ€™s revolutionize AI prompt optimization together!** ğŸš€

