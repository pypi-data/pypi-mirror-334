
测试结果: 
结论是：大概能达到纯显卡（75W，更高的没测）二分之一或三分之一的性能，显存不够的可以用用，主要是卷积层，卷积层cpu计算耗时很大，并且神经网络参数相对较少，线性层感觉cpu和显卡本来就差不太多

环境: 
    笔记本（游戏本）
    显卡: RTX4060 8GB 75W残血版
    CPU: i7-13700H
    内存: 16GB

1）线性层：
训练模式：
python -m buildz.gpuz.test.test_linear_demo train cuda,cache,cpu
结果：
data size: 0.457763671875 MB
Model Size: 1.7890334129333496 GB
Analyze
    mean time cost not used DictCache: 4.274392604827881 sec
    mean time cost using DictCache: 4.48450231552124 sec
    mean time cost using CPU: 24.141416311264038 sec

用不用DictCache耗时都是4秒左右，猜测是因为显存足够，显存里自己做了缓存
先占掉4GB显存再测试：
占用4GB显存（开另一个命令行窗口执行）
python -m buildz.gpuz.test.take_gpu_mem 20
时间测试（去掉cuda是因为显存不够，全部用cuda会直接报错显存不足，根本用不了）：
python -m buildz.gpuz.test.test_linear_demo train cache,cpu
Analyze
    mean time cost using DictCache: 12.55063670873642 sec
    mean time cost using CPU: 23.80371403694153 sec

用DictCache要12.6秒左右，性能推测是全部用显存的1/3，但起码比CPU快

测试模式：
python -m buildz.gpuz.test.test_linear_demo eval cuda,cache,cpu
Analyze
    mean time cost not used DictCache: 0.022499561309814453 sec
    mean time cost using DictCache: 1.3205116987228394 sec
    mean time cost using CPU: 0.3452974557876587 sec

测试模式DictCache比CPU还慢，没啥好说的，以测试结果为准，结论是测试模式线性层有显存用显存，没显存用CPU，尽量别用DictCache，猜测是因为测试模式下每个小模型的计算量很小，速度很快，这时候就显得显存和内存之间的传输很消耗时间

2）卷积层：
python -m buildz.gpuz.test.test_resnet_demo train cuda,cache,cpu
结果：
data size: 60.0 MB
Model Size: 2.75390625 MB
Analyze
    mean time cost not used DictCache: 4.0497170554267035 sec
    mean time cost using DictCache: 8.11503267288208 sec
    mean time cost using CPU: 60.47528860304091 sec
CPU模式下卷积一直很慢，另外别看模型参数很小，全放显存的时候8GB显卡直接占满了
