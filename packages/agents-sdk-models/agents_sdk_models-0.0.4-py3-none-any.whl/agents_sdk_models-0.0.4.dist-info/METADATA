Metadata-Version: 2.4
Name: agents-sdk-models
Version: 0.0.4
Summary: Model adapters for OpenAI Agents SDK
License-File: LICENSE
Requires-Python: >=3.11
Requires-Dist: openai-agents==0.0.4
Requires-Dist: openai>=1.66.2
Provides-Extra: examples
Requires-Dist: pydantic<3,>=2.10; extra == 'examples'
Description-Content-Type: text/markdown

# Agents SDK Models ğŸ¤–ğŸ”Œ

[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![OpenAI Agents](https://img.shields.io/badge/OpenAI-Agents-green.svg)](https://github.com/openai/openai-agents-python)

A collection of model adapters for OpenAI Agents SDK, allowing you to use various LLM providers with a unified interface! ğŸš€

## ğŸŒŸ Features

- ğŸ”„ **Unified Interface**: Use the same OpenAI Agents SDK interface with multiple model providers
- ğŸ§© **Multiple Models**: Support for Ollama, Google Gemini, and Anthropic Claude
- ğŸ“Š **Structured Output**: All models support structured output using Pydantic models
- ğŸŒŠ **Streaming**: Support for streaming responses (where available)
- ğŸ¤” **Thinking**: Enable extended thinking capabilities for complex reasoning (Claude)

## ğŸ› ï¸ Installation

```bash
# Clone the repository
git clone https://github.com/yourusername/agents-sdk-models.git
cd agents-sdk-models

# Create and activate a virtual environment
python -m venv .venv
.venv\Scripts\activate  # Windows
source .venv/bin/activate  # Linux/Mac

# Install the package in development mode
pip install -e .
```

## ğŸš€ Quick Start

### Ollama

```python
import asyncio
from agents import Agent, Runner
from agents_sdk_models import OllamaModel

async def main():
    # Initialize the Ollama model
    model = OllamaModel(
        model="llama3",  # or any other model available in your Ollama instance
        temperature=0.7
    )
    
    # Create an agent with the model
    agent = Agent(
        name="Assistant",
        instructions="You are a helpful assistant.",
        model=model
    )
    
    # Run the agent
    response = await Runner.run(agent, "What is your name and what can you do?")
    print(response.final_output)

if __name__ == "__main__":
    asyncio.run(main())
```

### Google Gemini

```python
import asyncio
import os
from agents import Agent, Runner
from agents_sdk_models import GeminiModel

async def main():
    # Get API key from environment variable
    api_key = os.environ.get("GOOGLE_API_KEY")
    
    # Initialize the Gemini model
    model = GeminiModel(
        model="gemini-1.5-pro",
        temperature=0.7,
        api_key=api_key
    )
    
    # Create an agent with the model
    agent = Agent(
        name="Assistant",
        instructions="You are a helpful assistant.",
        model=model
    )
    
    # Run the agent
    response = await Runner.run(agent, "What is your name and what can you do?")
    print(response.final_output)

if __name__ == "__main__":
    asyncio.run(main())
```

### Anthropic Claude

```python
import asyncio
import os
from agents import Agent, Runner
from agents_sdk_models import ClaudeModel

async def main():
    # Get API key from environment variable
    api_key = os.environ.get("ANTHROPIC_API_KEY")
    
    # Initialize the Claude model
    model = ClaudeModel(
        model="claude-3-sonnet-20240229",
        temperature=0.7,
        api_key=api_key,
        thinking=True  # Enable thinking for complex reasoning
    )
    
    # Create an agent with the model
    agent = Agent(
        name="Assistant",
        instructions="You are a helpful assistant.",
        model=model
    )
    
    # Run the agent
    response = await Runner.run(agent, "What is your name and what can you do?")
    print(response.final_output)

if __name__ == "__main__":
    asyncio.run(main())
```

## ğŸ“Š Structured Output

All models support structured output using Pydantic models:

```python
from pydantic import BaseModel
from typing import List

class WeatherInfo(BaseModel):
    location: str
    temperature: float
    condition: str
    recommendation: str

class WeatherReport(BaseModel):
    report_date: str
    locations: List[WeatherInfo]

# Create an agent with structured output
agent = Agent(
    name="Weather Reporter",
    model=model,
    instructions="You are a helpful weather reporter.",
    output_type=WeatherReport
)

# Get structured response
response = await Runner.run(agent, "What's the weather like in Tokyo, Osaka, and Sapporo?")
weather_report = response.final_output  # This is a WeatherReport object
```

## ğŸ”§ Supported Environments

- **Operating Systems**: Windows, macOS, Linux
- **Python Version**: 3.11+
- **Dependencies**: 
  - openai>=1.66.2
  - openai-agents==0.0.4
  - pydantic>=2.10, <3
  - ollama>=0.4.7 (for Ollama support)

## ğŸ“ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgements

- [OpenAI Agents SDK](https://github.com/openai/openai-agents-python)
- [Ollama](https://ollama.ai/)
- [Google Gemini](https://ai.google.dev/)
- [Anthropic Claude](https://www.anthropic.com/claude)
