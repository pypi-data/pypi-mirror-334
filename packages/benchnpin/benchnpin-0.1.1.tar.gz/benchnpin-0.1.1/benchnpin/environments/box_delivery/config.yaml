##############################################
# config for loading box-delivery simulation #
##############################################
### GLOBAL PARAMS
output_dir: "logs/" # 'output/trial0'

plot:
  y_axis_limit: 18  # limits the y-axis of the plot
  show: false       # true will show planner plots

teleop_mode: false     # when using teleoperation mode, control both forward and angular speed

render_scale: 30      # scale renderer window to fit screen size

# parameters for low-dim environment
low_dim_state: false
fixed_trial_idx: 1

### SIMULATION PARAMS
render:
  log_obs: false        # whether to log occupancy observation
  show: true            # if true display the environment
  show_obs: false       # if true show occupancy observation
  frequency: 20         # frequency of rendering
sim:
  t_max: 2000  # max number of iterations in simulation loop (originally 5000)
  steps: 100    # number of simulation steps per iteration (originally 10)
  gravity: !!python/tuple
    - 0
    - 0
  iterations: 10  # controls accuracy of pymunk solver i.e. simulation accuracy, default is 10
  damping: 0      # damping to body velocities
anim:
  save: true               # if true save to disk animation plots
  show: true                # if true show animation plots
  plot_steps: 50            # steps between plot updates
  plan_steps: 10            # steps between obstacle and planner updates
  inf_stream: false         # if true then infinite obstacle stream mode is enabled
  move_yaxis_threshold: 10  # distance traveled before y-axis moves

### CONTROLLER PARAMS
controller:
  dt: 0.2  # the agent dynamics model was discretized with this dt (originally 0.02)
  # target speed
  target_speed: 0.3  # m/s

boxes:
  num_boxes_small: 10
  num_boxes_large: 20
  box_size: 0.44
  min_box_dist: 0.62       # minimum box distance during random initialization
  box_density: 0.001

agent:
  action_type: 'position' # options are velocity, heading, position
  step_size: 1.25 # distance travelled per step in heading control
  random_start: true
  mass: 1  # mass of the robot
  padding: 0.25  # adds padding to ship footprint
  length: 0.8
  width: 0.7
  vertices: [
              [0.4, -0.35],
              [0.4, 0.35],
              [-0.4, 0.25],
              [-0.4, -0.25]
              ]
  wheel_vertices: [
    # left
    [
        [-0.4, 0.2],
        [-0.4, 0.3],
        [-0.15, 0.3], 
        [-0.15, 0.2]
    ],

    # right
    [
        [-0.4, -0.2],
        [-0.4, -0.3],
        [-0.15, -0.3], 
        [-0.15, -0.2]
    ],
  ]

### ENVIRONMENT PARAMS
env:
  obstacle_config: small_empty # options are small_empty, small_columns, large_columns, large_divider
  room_length: 10
  room_width_small: 5
  room_width_large: 10
  receptacle_width: 1.5
  shortest_path_channel_scale: 0.25
  local_map_pixel_width: 224
  local_map_pixel_width_sam: 96
  local_map_width: 10 # 10 meters
  wall_thickness: 14
  invert_receptacle_map: false

misc:
  ministep_size: 2.5
  inactivity_cutoff_sam: 100
  inactivity_cutoff: 200
  random_seed: 42

rewards_sam:
  partial_rewards_scale: 0.2
  goal_reward: 1.0
  collision_penalty: 0.25
  non_movement_penalty: 0.25
  correct_direction_reward_scale: 1

rewards:
  partial_rewards_scale: 0.2
  goal_reward: 10.0
  collision_penalty: 0.25
  non_movement_penalty: 0
  correct_direction_reward_scale: 3

train:
  train_mode: false
  job_type: 'ppo'
  job_name: 'ppo_model'
  batch_size: 32
  checkpoint_freq: 6000
  exploration_timesteps: 6000
  final_exploration: 0.01
  gamma: 0.99
  grad_norm_clipping: 10
  job_id_to_resume: null
  learning_rate: 0.01
  learning_starts: 1000
  n_epochs: 10
  n_steps: 256
  replay_buffer_size: 10000
  resume_training: false
  target_update_freq: 1000
  total_timesteps: 60000
  use_correct_direction_reward: true
  verbose: 2
  weight_decay: 0.0001

evaluate:
  eval_mode: true
  num_eps: 2
  policy_types: ['ppo', 'sac', 'sam']  # list of policy types to evaluate
  action_types: ['heading', 'heading', 'position']  # list of action types to evaluate
  models: ['ppo_small_empty', 'sac_small_empty', 'sam_small_empty']  # list of model names to evaluate
  obs_configs: ['small_empty', 'small_empty', 'small_empty']  # list of obstacle configurations to evaluate
