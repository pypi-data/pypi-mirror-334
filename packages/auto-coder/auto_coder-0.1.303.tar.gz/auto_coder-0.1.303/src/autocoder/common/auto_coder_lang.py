import locale
from byzerllm.utils import format_str_jinja2

MESSAGES = {
    "en": {
        "file_scored_message": "File scored: {{file_path}} - Score: {{score}}",
        "invalid_file_pattern": "Invalid file pattern: {{file_pattern}}. e.g. regex://.*/package-lock\\.json",
        "config_validation_error": "Config validation error: {{error}}",
        "invalid_boolean_value": "Value '{{value}}' is not a valid boolean(true/false)",
        "invalid_integer_value": "Value '{{value}}' is not a valid integer",
        "invalid_float_value": "Value '{{value}}' is not a valid float",
        "invalid_type_value": "Value '{{value}}' is not a valid type (expected: {{types}})",
        "value_out_of_range": "Value {{value}} is out of allowed range({{min}}~{{max}})",
        "invalid_choice": "Value '{{value}}' is not in allowed options({{allowed}})",
        "unknown_config_key": "Unknown config key '{{key}}'",
        "model_not_found": "Model '{{model}}' is not configured in models.yml",
        "required_without_default": "Config key '{{key}}' requires explicit value",
        "auto_command_action_break": "Command {{command}} execution failed (got {{action}} result), no result can be obtained, please try again",
        "auto_command_break": "Auto command execution failed to execute command: {{command}}",
        "auto_command_executing": "\n\n============= Executing command: {{command}} =============\n\n",
        "model_provider_select_title": "Select Model Provider",
        "auto_config_analyzing": "Analyzing configuration...",
        "config_delete_success": "Successfully deleted configuration: {{key}}",
        "config_not_found": "Configuration not found: {{key}}",
        "config_invalid_format": "Invalid configuration format. Expected 'key:value'",
        "config_value_empty": "Configuration value cannot be empty",
        "config_set_success": "Successfully set configuration: {{key}} = {{value}}",
        "model_provider_select_text": "Please select your model provider:",
        "model_provider_volcano": "Volcano Engine",
        "model_provider_siliconflow": "SiliconFlow AI",
        "model_provider_deepseek": "DeepSeek Official",        
        "model_provider_api_key_title": "API Key",
        "model_provider_volcano_api_key_text": "Please enter your Volcano Engine API key:",
        "model_provider_volcano_r1_text": "Please enter your Volcano Engine R1 endpoint (format: ep-20250204215011-vzbsg):",
        "model_provider_volcano_v3_text": "Please enter your Volcano Engine V3 endpoint (format: ep-20250204215011-vzbsg):",
        "model_provider_siliconflow_api_key_text": "Please enter your SiliconFlow AI API key:",
        "model_provider_deepseek_api_key_text": "Please enter your DeepSeek API key:",
        "model_provider_selected": "Provider configuration completed successfully! You can use /models command to view, add and modify all models later.",
        "model_provider_success_title": "Success",
        "index_file_filtered": "File {{file_path}} is filtered by model {{model_name}} restrictions",
        "models_no_active": "No active models found",
        "models_speed_test_results": "Model Speed Test Results",
        "models_testing": "Testing model: {{name}}...",
        "models_testing_start": "Starting speed test for all active models...",
        "models_testing_progress": "Testing progress: {{ completed }}/{{ total }} models",
        "generation_cancelled": "[Interrupted] Generation cancelled",
        "model_not_found": "Model {{model_name}} not found",
        "generating_shell_script": "Generating Shell Script",
        "new_session_started": "New session started. Previous chat history has been archived.",
        "memory_save_success": "‚úÖ Saved to your memory(path: {{path}})",
        "file_decode_error": "Failed to decode file: {{file_path}}. Tried encodings: {{encodings}}",
        "file_write_error": "Failed to write file: {{file_path}}. Error: {{error}}",
        "yaml_load_error": "Error loading yaml file {{yaml_file}}: {{error}}",
        "git_command_error": "Git command execution error: {{error}}",
        "get_commit_diff_error": "Error getting commit diff: {{error}}",
        "no_latest_commit": "Unable to get latest commit information",
        "code_review_error": "Code review process error: {{error}}",
        "index_file_too_large": "‚ö†Ô∏è File {{ file_path }} is too large ({{ file_size }} > {{ max_length }}), splitting into chunks...",
        "index_update_success": "‚úÖ {{ model_name }} Successfully updated index for {{ file_path }} (md5: {{ md5 }}) in {{ duration }}s, input_tokens: {{ input_tokens }}, output_tokens: {{ output_tokens }}, input_cost: {{ input_cost }}, output_cost: {{ output_cost }}",
        "index_build_error": "‚ùå {{ model_name }} Error building index for {{ file_path }}: {{ error }}",
        "index_build_summary": "üìä Total Files: {{ total_files }}, Need to Build Index: {{ num_files }}",
        "building_index_progress": "‚è≥ Building Index: {{ counter }}/{{ num_files }}...",
        "index_source_dir_mismatch": "‚ö†Ô∏è Source directory mismatch (file_path: {{ file_path }}, source_dir: {{ source_dir }})",
        "index_related_files_fail": "‚ö†Ô∏è Failed to find related files for chunk {{ chunk_count }}",
        "index_threads_completed": "‚úÖ Completed {{ completed_threads }}/{{ total_threads }} threads",
        "index_related_files_fail": "‚ö†Ô∏è Failed to find related files for chunk {{ chunk_count }}",
        "index_file_removed": "üóëÔ∏è Removed non-existent file index: {{ file_path }}",
        "index_file_saved": "üíæ Saved index file, updated {{ updated_files }} files, removed {{ removed_files }} files, input_tokens: {{ input_tokens }}, output_tokens: {{ output_tokens }}, input_cost: {{ input_cost }}, output_cost: {{ output_cost }}",
        "human_as_model_instructions": (
            "You are now in Human as Model mode. The content has been copied to your clipboard.\n"
            "The system is waiting for your input. When finished, enter 'EOF' on a new line to submit.\n"
            "Use '/break' to exit this mode. If you have issues with copy-paste, use '/clear' to clean and paste again."
        ),
        "clipboard_not_supported": (
            "pyperclip not installed or clipboard is not supported, instruction will not be copied to clipboard."
        ),
        "human_as_model_instructions_no_clipboard": (
            "You are now in Human as Model mode. [bold red]The content could not be copied to your clipboard.[/bold red]\n"
            "but you can copy prompt from output.txt file.\n"
            "The system is waiting for your input. When finished, enter 'EOF' on a new line to submit.\n"
            "Use '/break' to exit this mode. If you have issues with copy-paste, use '/clear' to clean and paste again."
        ),
        "phase1_processing_sources": "Phase 1: Processing REST/RAG/Search sources...",
        "phase2_building_index": "Phase 2: Building index for all files...",
        "phase6_file_selection": "Phase 6: Processing file selection and limits...",
        "phase7_preparing_output": "Phase 7: Preparing final output...",
        "chat_human_as_model_instructions": (
            "Chat is now in Human as Model mode.\n"
            "The question has been copied to your clipboard.\n"
            "Please use Web version model to get the answer.\n"
            "Or use /conf human_as_model:false to close this mode and get the answer in terminal directly."
            "Paste the answer to the input box below, use '/break' to exit, '/clear' to clear the screen, '/eof' to submit."
        ),
        "code_generation_start": "Auto generate the code...",
        "code_generation_complete": "{{ model_names}} Code generation completed in {{ duration }} seconds (sampling_count: {{ sampling_count }}), input_tokens_count: {{ input_tokens }}, generated_tokens_count: {{ output_tokens }}, input_cost: {{ input_cost }}, output_cost: {{ output_cost }}, speed: {{ speed }} tokens/s",
        "code_merge_start": "Auto merge the code...",
        "code_execution_warning": "Content(send to model) is {{ content_length }} tokens (you may collect too much files), which is larger than the maximum input length {{ max_length }}",
        "quick_filter_start": "{{ model_name }} Starting filter context(quick_filter)...",
        "normal_filter_start": "{{ model_name }} Starting filter context(normal_filter)...",
        "pylint_check_failed": "‚ö†Ô∏è Pylint check failed: {{ error_message }}",
        "pylint_error": "‚ùå Error running pylint: {{ error_message }}",
        "unmerged_blocks_warning": "‚ö†Ô∏è Found {{ num_blocks }} unmerged blocks, the changes will not be applied. Please review them manually then try again.",
        "pylint_file_check_failed": "‚ö†Ô∏è Pylint check failed for {{ file_path }}. Changes not applied. Error: {{ error_message }}",
        "merge_success": "‚úÖ Merged changes in {{ num_files }} files {{ num_changes }}/{{ total_blocks }} blocks.",
        "no_changes_made": "‚ö†Ô∏è No changes were made to any files.",
        "files_merged": "‚úÖ Merged {{ total }} files into the project.",
        "merge_failed": "‚ùå Merge file {{ path }} failed: {{ error }}",
        "files_merged_total": "‚úÖ Merged {{ total }} files into the project.",
        "ranking_skip": "Only 1 candidate, skip ranking",
        "ranking_start": "Start ranking {{ count }} candidates using model {{ model_name }}",
        "ranking_failed_request": "Ranking request failed: {{ error }}",
        "ranking_all_failed": "All ranking requests failed",
        "ranking_complete": "{{ model_names }} Ranking completed in {{ elapsed }}s, total voters: {{ total_tasks }}, best candidate index: {{ best_candidate }}, scores: {{ scores }}, input_tokens: {{ input_tokens }}, output_tokens: {{ output_tokens }}, input_cost: {{ input_cost }}, output_cost: {{ output_cost }}, speed: {{ speed }} tokens/s",
        "ranking_process_failed": "Ranking process failed: {{ error }}",
        "ranking_failed": "Ranking failed in {{ elapsed }}s, using original order",
        "begin_index_source_code": "üöÄ Begin to index source code in {{ source_dir }}",
        "stream_out_stats": "Model: {{ model_name }}, Total time: {{ elapsed_time }} seconds, First token time: {{ first_token_time }} seconds, Speed: {{ speed }} tokens/s, Input tokens: {{ input_tokens }}, Output tokens: {{ output_tokens }}, Input cost: {{ input_cost }}, Output cost: {{ output_cost }}",
        "quick_filter_stats": "{{ model_names }} Quick filter completed in {{ elapsed_time }} seconds, input tokens: {{ input_tokens }}, output tokens: {{ output_tokens }}, input cost: {{ input_cost }}, output cost: {{ output_cost }} speed: {{ speed }} tokens/s",
        "upsert_file": "‚úÖ Updated file: {{ file_path }}",
        "unmerged_blocks_title": "Unmerged Blocks",
        "merged_blocks_title": "Merged Changes",
        "quick_filter_title": "{{ model_name }} is analyzing how to filter context...",
        "quick_filter_failed": "‚ùå Quick filter failed: {{ error }}. ",
        "unmerged_file_path": "File: {{file_path}}",
        "unmerged_search_block": "Search Block({{similarity}}):",
        "unmerged_replace_block": "Replace Block:",
        "unmerged_blocks_total": "Total unmerged blocks: {{num_blocks}}",
        "git_init_required": "‚ö†Ô∏è auto_merge only applies to git repositories.\n\nPlease try using git init in the source directory:\n\n```shell\ncd {{ source_dir }}\ngit init.\n```\n\nThen run auto - coder again.\nError: {{ error }}",
        "quick_filter_reason": "Auto get(quick_filter mode)",
        "quick_filter_too_long": "‚ö†Ô∏è index file is too large ({{ tokens_len }}/{{ max_tokens }}). The query will be split into {{ split_size }} chunks.",
        "quick_filter_tokens_len": "üìä Current index size: {{ tokens_len }} tokens",
        "estimated_chat_input_tokens": "Estimated chat input tokens: {{ estimated_input_tokens }}",
        "estimated_input_tokens_in_generate": "Estimated input tokens in generate ({{ generate_mode }}): {{ estimated_input_tokens_in_generate }}",        
        "model_has_access_restrictions": "{{model_name}} has access restrictions, cannot use the current function",
        "auto_command_not_found": "Auto command not found: {{command}}. Please check your input and try again.",
        "auto_command_failed": "Auto command failed: {{error}}. Please check your input and try again.",
        "command_execution_result": "{{action}} execution result",
        "satisfied_prompt": "Requirements satisfied, no further action needed",
        "auto_command_analyzed": "Selected command",
        "invalid_enum_value": "Value '{{value}}' is not in allowed values ({{allowed}})",
        "no_changes_made": "‚ö†Ô∏è no changes made, the reason may be that the text block generated by the coding function has a problem, so it cannot be merged into the project",
        "conversation_pruning_start": "‚ö†Ô∏è Conversation pruning started, total tokens: {{total_tokens}}, safe zone: {{safe_zone}}",
        "invalid_file_number": "‚ö†Ô∏è Invalid file number {{file_number}}, total files: {{total_files}}",
        "all_merge_results_failed": "‚ö†Ô∏è All merge attempts failed, returning first candidate",
        "only_one_merge_result_success": "‚úÖ Only one merge result succeeded, returning that candidate",
        "conf_import_success": "Successfully imported configuration: {{path}}",
        "conf_export_success": "Successfully exported configuration: {{path}}",
        "conf_import_error": "Error importing configuration: {{error}}",
        "conf_export_error": "Error exporting configuration: {{error}}",
        "conf_import_invalid_format": "Invalid import configuration format, expected 'key:value'",
        "conf_export_invalid_format": "Invalid export configuration format, expected 'key:value'",
        "conf_import_file_not_found": "Import configuration file not found: {{file_path}}",
        "conf_export_file_not_found": "Export configuration file not found: {{file_path}}",
        "conf_import_file_empty": "Import configuration file is empty: {{file_path}}",
        "conf_export_file_empty": "Export configuration file is empty: {{file_path}}",
        "generated_shell_script": "Generated Shell Script",
        "confirm_execute_shell_script": "Do you want to execute this shell script?",
        "shell_script_not_executed": "Shell script was not executed",
        "conf_not_found": "Configuration file not found: {{path}}",
        "index_export_success": "Index exported successfully: {{path}}",
        "index_import_success": "Index imported successfully: {{path}}",
        "edits_title": "edits",
        "diff_blocks_title":"diff blocks",
        "index_exclude_files_error": "index filter exclude files fail: {{ error }}",
        "file_sliding_window_processing": "File {{ file_path }} is too large ({{ tokens }} tokens), processing with sliding window...",
        "file_snippet_processing": "Processing file {{ file_path }} with code snippet extraction...",
        "context_pruning_start": "‚ö†Ô∏è Context pruning started. Total tokens: {{ total_tokens }} (max allowed: {{ max_tokens }}). Applying strategy: {{ strategy }}.",
        "context_pruning_reason": "Context length exceeds maximum limit ({{ total_tokens }} > {{ max_tokens }}). Pruning is required to fit within the model's context window.",
        "rank_code_modification_title": "{{model_name}} ranking codes",
        "sorted_files_message": "Reordered files:\n{% for file in files %}- {{ file }}\n{% endfor %}",
        "estimated_input_tokens_in_ranking": "estimate input token {{ estimated_input_tokens }} when ranking",
        "file_snippet_procesed": "{{ file_path }} processed with tokens: {{ tokens }} => {{ snippet_tokens }}. Current total tokens: {{ total_tokens }}",
        "tool_ask_user": "Your Reply: ",
        "tool_ask_user_accept":"Your Response received",
        "auto_web_analyzing": "Analyzing web automation task...",
        "auto_web_analyzed": "Web automation task analysis completed",
        "executing_web_action": "Executing action: {{action}} - {{description}}",
        "executing_step": "Executing step {{step}}: {{description}}",
        "operation_cancelled": "Operation cancelled",
        "element_not_found": "Element not found: {{element}}",
        "analyzing_results": "Analyzing execution results...",
        "next_steps_determined": "Next steps determined",
        "max_iterations_reached": "Max iterations reached ({max_iterations})",
        "action_verification_failed": "Action verification failed: {{action}} - {{reason}}",
        "action_succeeded": "Action succeeded: {{action}}",
        "replanned_actions": "Replanned {{count}} actions",
        "web_automation_ask_user": "Your answer: ",
        "filter_mode_normal": "Using normal filter mode for index processing...",
        "filter_mode_big": "Index file is large ({{ tokens_len }} tokens), using big_filter mode for processing...",
        "filter_mode_super_big": "Index file is very large ({{ tokens_len }} tokens), using super_big_filter mode for processing...",
        "super_big_filter_failed": "‚ùå Super big filter failed: {{ error }}.",
        "super_big_filter_stats": "{{ model_names }} Super big filter completed in {{ elapsed_time }} seconds, input tokens: {{ input_tokens }}, output tokens: {{ output_tokens }}, input cost: {{ input_cost }}, output cost: {{ output_cost }}, speed: {{ speed }} tokens/s, chunk_index: {{ chunk_index }}",
        "super_big_filter_splitting": "‚ö†Ô∏è Index file is extremely large ({{ tokens_len }}/{{ max_tokens }}). The query will be split into {{ split_size }} chunks for processing.",
        "super_big_filter_title": "{{ model_name }} is analyzing how to filter extremely large context...",
        "mcp_server_info_error": "Error getting MCP server info: {{ error }}",
        "mcp_server_info_title": "Connected MCP Server Info",
        "no_commit_file_name": "Cannot get the file name of the commit_id in the actions directory: {{commit_id}}",
        "yaml_update_success": "‚úÖ Successfully updated YAML file: {{yaml_file}}",
        "yaml_save_error": "‚ùå Error saving YAML file {{yaml_file}}: {{error}}",
    },
    "zh": {
        "file_sliding_window_processing": "Êñá‰ª∂ {{ file_path }} ËøáÂ§ß ({{ tokens }} tokens)ÔºåÊ≠£Âú®‰ΩøÁî®ÊªëÂä®Á™óÂè£Â§ÑÁêÜ...",
        "file_snippet_processing": "Ê≠£Âú®ÂØπÊñá‰ª∂ {{ file_path }} ËøõË°å‰ª£Á†ÅÁâáÊÆµÊèêÂèñ...",
        "context_pruning_start": "‚ö†Ô∏è ÂºÄÂßã‰∏ä‰∏ãÊñáÂâ™Êûù„ÄÇÊÄªtokenÊï∞: {{ total_tokens }} (ÊúÄÂ§ßÂÖÅËÆ∏: {{ max_tokens }})„ÄÇÊ≠£Âú®Â∫îÁî®Á≠ñÁï•: {{ strategy }}„ÄÇ",
        "context_pruning_reason": "‰∏ä‰∏ãÊñáÈïøÂ∫¶Ë∂ÖËøáÊúÄÂ§ßÈôêÂà∂ ({{ total_tokens }} > {{ max_tokens }})„ÄÇÈúÄË¶ÅËøõË°åÂâ™Êûù‰ª•ÈÄÇÈÖçÊ®°ÂûãÁöÑ‰∏ä‰∏ãÊñáÁ™óÂè£„ÄÇ",
        "file_scored_message": "Êñá‰ª∂ËØÑÂàÜ: {{file_path}} - ÂàÜÊï∞: {{score}}",
        "invalid_file_pattern": "Êó†ÊïàÁöÑÊñá‰ª∂Ê®°Âºè: {{file_pattern}}. ‰æãÂ¶Ç: regex://.*/package-lock\\.json",
        "conf_not_found": "Êú™ÊâæÂà∞ÈÖçÁΩÆÊñá‰ª∂: {{path}}",
        "conf_import_success": "ÊàêÂäüÂØºÂÖ•ÈÖçÁΩÆ: {{path}}",
        "conf_export_success": "ÊàêÂäüÂØºÂá∫ÈÖçÁΩÆ: {{path}}",
        "conf_import_error": "ÂØºÂÖ•ÈÖçÁΩÆÂá∫Èîô: {{error}}",
        "conf_export_error": "ÂØºÂá∫ÈÖçÁΩÆÂá∫Èîô: {{error}}",
        "conf_import_invalid_format": "ÂØºÂÖ•ÈÖçÁΩÆÊ†ºÂºèÊó†Êïà, Â∫î‰∏∫ 'key:value' Ê†ºÂºè",
        "conf_export_invalid_format": "ÂØºÂá∫ÈÖçÁΩÆÊ†ºÂºèÊó†Êïà, Â∫î‰∏∫ 'key:value' Ê†ºÂºè",
        "conf_import_file_not_found": "Êú™ÊâæÂà∞ÂØºÂÖ•ÈÖçÁΩÆÊñá‰ª∂: {{file_path}}",
        "conf_export_file_not_found": "Êú™ÊâæÂà∞ÂØºÂá∫ÈÖçÁΩÆÊñá‰ª∂: {{file_path}}",
        "conf_import_file_empty": "ÂØºÂÖ•ÈÖçÁΩÆÊñá‰ª∂‰∏∫Á©∫: {{file_path}}",
        "conf_export_file_empty": "ÂØºÂá∫ÈÖçÁΩÆÊñá‰ª∂‰∏∫Á©∫: {{file_path}}",
        "generated_shell_script": "ÁîüÊàêÁöÑ Shell ËÑöÊú¨",
        "confirm_execute_shell_script": "ÊÇ®Ë¶ÅÊâßË°åÊ≠§ shell ËÑöÊú¨ÂêóÔºü",
        "shell_script_not_executed": "Shell ËÑöÊú¨Êú™ÊâßË°å",
        "config_validation_error": "ÈÖçÁΩÆÈ™åËØÅÈîôËØØ: {{error}}",
        "invalid_boolean_value": "ÂÄº '{{value}}' ‰∏çÊòØÊúâÊïàÁöÑÂ∏ÉÂ∞îÂÄº(true/false)",
        "invalid_integer_value": "ÂÄº '{{value}}' ‰∏çÊòØÊúâÊïàÁöÑÊï¥Êï∞",
        "invalid_float_value": "ÂÄº '{{value}}' ‰∏çÊòØÊúâÊïàÁöÑÊµÆÁÇπÊï∞",
        "invalid_type_value": "ÂÄº '{{value}}' ‰∏çÊòØÊúâÊïàÁöÑÁ±ªÂûã (ÊúüÊúõ: {{types}})",
        "value_out_of_range": "ÂÄº {value} Ë∂ÖÂá∫ÂÖÅËÆ∏ËåÉÂõ¥({min}~{max})",
        "invalid_choice": "ÂÄº '{value}' ‰∏çÂú®ÂÖÅËÆ∏ÈÄâÈ°π‰∏≠({allowed})",
        "unknown_config_key": "Êú™Áü•ÁöÑÈÖçÁΩÆÈ°π '{key}'",
        "model_not_found": "Ê®°Âûã '{model}' Êú™Âú® models.yml ‰∏≠ÈÖçÁΩÆ",
        "required_without_default": "ÈÖçÁΩÆÈ°π '{key}' ÈúÄË¶ÅÊòéÁ°ÆËÆæÁΩÆÂÄº",
        "auto_command_action_break": "ÂëΩ‰ª§ {{command}} ÊâßË°åÂ§±Ë¥•ÔºàËé∑ÂèñÂà∞‰∫Ü {{action}} ÁöÑÁªìÊûúÔºâÔºåÊó†Ê≥ïËé∑Âæó‰ªª‰ΩïÁªìÊûú,ËØ∑ÈáçËØï",
        "auto_command_break": "Ëá™Âä®ÂëΩ‰ª§ÊâßË°åÂ§±Ë¥•: {{command}}",
        "auto_command_executing": "\n\n============= Ê≠£Âú®ÊâßË°åÊåá‰ª§: {{command}} =============\n\n",
        "model_provider_select_title": "ÈÄâÊã©Ê®°Âûã‰æõÂ∫îÂïÜ",
        "auto_config_analyzing": "Ê≠£Âú®ÂàÜÊûêÈÖçÁΩÆ...",
        "config_delete_success": "ÊàêÂäüÂà†Èô§ÈÖçÁΩÆ: {{key}}",
        "config_not_found": "Êú™ÊâæÂà∞ÈÖçÁΩÆ: {{key}}",
        "config_invalid_format": "ÈÖçÁΩÆÊ†ºÂºèÊó†ÊïàÔºåÂ∫î‰∏∫'key:value'Ê†ºÂºè",
        "config_value_empty": "ÈÖçÁΩÆÂÄº‰∏çËÉΩ‰∏∫Á©∫",
        "config_set_success": "ÊàêÂäüËÆæÁΩÆÈÖçÁΩÆ: {{key}} = {{value}}",
        "model_provider_select_text": "ËØ∑ÈÄâÊã©ÊÇ®ÁöÑÊ®°Âûã‰æõÂ∫îÂïÜÔºö",
        "model_provider_volcano": "ÁÅ´Â±±ÊñπËàü",
        "model_provider_siliconflow": "Á°ÖÂü∫ÊµÅÂä®",
        "model_provider_deepseek": "DeepSeekÂÆòÊñπ",        
        "model_provider_api_key_title": "APIÂØÜÈí•",
        "model_provider_volcano_api_key_text": "ËØ∑ËæìÂÖ•ÊÇ®ÁöÑÁÅ´Â±±ÊñπËàüAPIÂØÜÈí•Ôºö",
        "model_provider_volcano_r1_text": "ËØ∑ËæìÂÖ•ÊÇ®ÁöÑÁÅ´Â±±ÊñπËàü R1 Êé®ÁêÜÁÇπ(Ê†ºÂºèÂ¶Ç: ep-20250204215011-vzbsg)Ôºö",
        "model_provider_volcano_v3_text": "ËØ∑ËæìÂÖ•ÊÇ®ÁöÑÁÅ´Â±±ÊñπËàü V3 Êé®ÁêÜÁÇπ(Ê†ºÂºèÂ¶Ç: ep-20250204215011-vzbsg)Ôºö",
        "model_provider_siliconflow_api_key_text": "ËØ∑ËæìÂÖ•ÊÇ®ÁöÑÁ°ÖÂü∫ÊµÅÂä®APIÂØÜÈí•Ôºö",
        "model_provider_deepseek_api_key_text": "ËØ∑ËæìÂÖ•ÊÇ®ÁöÑDeepSeek APIÂØÜÈí•Ôºö",
        "model_provider_selected": "‰æõÂ∫îÂïÜÈÖçÁΩÆÂ∑≤ÊàêÂäüÂÆåÊàêÔºÅÂêéÁª≠‰Ω†ÂèØ‰ª•‰ΩøÁî® /models ÂëΩ‰ª§ÔºåÊü•ÁúãÔºåÊñ∞Â¢ûÂíå‰øÆÊîπÊâÄÊúâÊ®°Âûã",
        "model_provider_success_title": "ÊàêÂäü",
        "index_file_filtered": "Êñá‰ª∂ {{file_path}} Ë¢´Ê®°Âûã {{model_name}} ÁöÑËÆøÈóÆÈôêÂà∂ËøáÊª§",
        "models_no_active": "Êú™ÊâæÂà∞ÊøÄÊ¥ªÁöÑÊ®°Âûã",
        "models_speed_test_results": "Ê®°ÂûãÈÄüÂ∫¶ÊµãËØïÁªìÊûú",
        "models_testing": "Ê≠£Âú®ÊµãËØïÊ®°Âûã: {{name}}...",
        "models_testing_start": "ÂºÄÂßãÂØπÊâÄÊúâÊøÄÊ¥ªÁöÑÊ®°ÂûãËøõË°åÈÄüÂ∫¶ÊµãËØï...",
        "generation_cancelled": "[Â∑≤‰∏≠Êñ≠] ÁîüÊàêÂ∑≤ÂèñÊ∂à",
        "model_not_found": "Êú™ÊâæÂà∞Ê®°Âûã: {{model_name}}",
        "generating_shell_script": "Ê≠£Âú®ÁîüÊàê Shell ËÑöÊú¨",
        "new_session_started": "Êñ∞‰ºöËØùÂ∑≤ÂºÄÂßã„ÄÇ‰πãÂâçÁöÑËÅäÂ§©ÂéÜÂè≤Â∑≤Â≠òÊ°£„ÄÇ",
        "memory_save_success": "‚úÖ Â∑≤‰øùÂ≠òÂà∞ÊÇ®ÁöÑËÆ∞ÂøÜ‰∏≠(Ë∑ØÂæÑ: {{path}})",
        "file_decode_error": "Êó†Ê≥ïËß£Á†ÅÊñá‰ª∂: {{file_path}}„ÄÇÂ∞ùËØïÁöÑÁºñÁ†Å: {{encodings}}",
        "file_write_error": "Êó†Ê≥ïÂÜôÂÖ•Êñá‰ª∂: {{file_path}}. ÈîôËØØ: {{error}}",
        "yaml_load_error": "Âä†ËΩΩYAMLÊñá‰ª∂Âá∫Èîô {{yaml_file}}: {{error}}",
        "git_command_error": "GitÂëΩ‰ª§ÊâßË°åÈîôËØØ: {{error}}",
        "get_commit_diff_error": "Ëé∑Âèñcommit diffÊó∂Âá∫Èîô: {{error}}",
        "no_latest_commit": "Êó†Ê≥ïËé∑ÂèñÊúÄÊñ∞ÁöÑÊèê‰∫§‰ø°ÊÅØ",
        "code_review_error": "‰ª£Á†ÅÂÆ°Êü•ËøáÁ®ãÂá∫Èîô: {{error}}",
        "index_file_too_large": "‚ö†Ô∏è Êñá‰ª∂ {{ file_path }} ËøáÂ§ß ({{ file_size }} > {{ max_length }}), Ê≠£Âú®ÂàÜÂùóÂ§ÑÁêÜ...",
        "index_update_success": "‚úÖ {{ model_name }} ÊàêÂäüÊõ¥Êñ∞ {{ file_path }} ÁöÑÁ¥¢Âºï (md5: {{ md5 }}), ËÄóÊó∂ {{ duration }} Áßí, ËæìÂÖ•tokenÊï∞: {{ input_tokens }}, ËæìÂá∫tokenÊï∞: {{ output_tokens }}, ËæìÂÖ•ÊàêÊú¨: {{ input_cost }}, ËæìÂá∫ÊàêÊú¨: {{ output_cost }}",
        "index_build_error": "‚ùå {{ model_name }} ÊûÑÂª∫ {{ file_path }} Á¥¢ÂºïÊó∂Âá∫Èîô: {{ error }}",
        "index_build_summary": "üìä ÊÄªÊñá‰ª∂Êï∞: {{ total_files }}, ÈúÄË¶ÅÊûÑÂª∫Á¥¢Âºï: {{ num_files }}",
        "building_index_progress": "‚è≥ Ê≠£Âú®ÊûÑÂª∫Á¥¢Âºï: {{ counter }}/{{ num_files }}...",
        "index_source_dir_mismatch": "‚ö†Ô∏è Ê∫êÁõÆÂΩï‰∏çÂåπÈÖç (Êñá‰ª∂Ë∑ØÂæÑ: {{ file_path }}, Ê∫êÁõÆÂΩï: {{ source_dir }})",
        "index_related_files_fail": "‚ö†Ô∏è Êó†Ê≥ï‰∏∫Âùó {{ chunk_count }} ÊâæÂà∞Áõ∏ÂÖ≥Êñá‰ª∂",
        "index_threads_completed": "‚úÖ Â∑≤ÂÆåÊàê {{ completed_threads }}/{{ total_threads }} ‰∏™Á∫øÁ®ã",
        "index_related_files_fail": "‚ö†Ô∏è Êó†Ê≥ï‰∏∫Âùó {{ chunk_count }} ÊâæÂà∞Áõ∏ÂÖ≥Êñá‰ª∂",
        "index_file_removed": "üóëÔ∏è Â∑≤ÁßªÈô§‰∏çÂ≠òÂú®ÁöÑÊñá‰ª∂Á¥¢ÂºïÔºö{{ file_path }}",
        "index_file_saved": "üíæ Â∑≤‰øùÂ≠òÁ¥¢ÂºïÊñá‰ª∂ÔºåÊõ¥Êñ∞‰∫Ü {{ updated_files }} ‰∏™Êñá‰ª∂ÔºåÁßªÈô§‰∫Ü {{ removed_files }} ‰∏™Êñá‰ª∂ÔºåËæìÂÖ•tokenÊï∞: {{ input_tokens }}, ËæìÂá∫tokenÊï∞: {{ output_tokens }}, ËæìÂÖ•ÊàêÊú¨: {{ input_cost }}, ËæìÂá∫ÊàêÊú¨: {{ output_cost }}",
        "human_as_model_instructions": (
            "ÊÇ®Áé∞Âú®Â§Ñ‰∫é‰∫∫Á±ª‰Ωú‰∏∫Ê®°ÂûãÊ®°Âºè„ÄÇÂÜÖÂÆπÂ∑≤Â§çÂà∂Âà∞ÊÇ®ÁöÑÂâ™Ë¥¥Êùø„ÄÇ\n"
            "Á≥ªÁªüÊ≠£Âú®Á≠âÂæÖÊÇ®ÁöÑËæìÂÖ•„ÄÇÂÆåÊàêÂêéÔºåÂú®Êñ∞Ë°åËæìÂÖ•'EOF'Êèê‰∫§„ÄÇ\n"
            "‰ΩøÁî®'/break'ÈÄÄÂá∫Ê≠§Ê®°Âºè„ÄÇÂ¶ÇÊûúÂ§çÂà∂Á≤òË¥¥ÊúâÈóÆÈ¢òÔºå‰ΩøÁî®'/clear'Ê∏ÖÁêÜÂπ∂ÈáçÊñ∞Á≤òË¥¥„ÄÇ"
        ),
        "clipboard_not_supported": (
            "Êú™ÂÆâË£ÖpyperclipÊàñ‰∏çÊîØÊåÅÂâ™Ë¥¥ÊùøÔºåÊåá‰ª§Â∞Ü‰∏ç‰ºöË¢´Â§çÂà∂Âà∞Ââ™Ë¥¥Êùø„ÄÇ"
        ),
        "human_as_model_instructions_no_clipboard": (
            "ÊÇ®Áé∞Âú®Â§Ñ‰∫é‰∫∫Á±ª‰Ωú‰∏∫Ê®°ÂûãÊ®°Âºè„ÄÇ[bold red]ÂÜÖÂÆπÊó†Ê≥ïÂ§çÂà∂Âà∞ÊÇ®ÁöÑÂâ™Ë¥¥Êùø„ÄÇ[/bold red]\n"
            "‰ΩÜÊÇ®ÂèØ‰ª•‰ªéoutput.txtÊñá‰ª∂Â§çÂà∂ÊèêÁ§∫„ÄÇ\n"
            "Á≥ªÁªüÊ≠£Âú®Á≠âÂæÖÊÇ®ÁöÑËæìÂÖ•„ÄÇÂÆåÊàêÂêéÔºåÂú®Êñ∞Ë°åËæìÂÖ•'EOF'Êèê‰∫§„ÄÇ\n"
            "‰ΩøÁî®'/break'ÈÄÄÂá∫Ê≠§Ê®°Âºè„ÄÇÂ¶ÇÊûúÂ§çÂà∂Á≤òË¥¥ÊúâÈóÆÈ¢òÔºå‰ΩøÁî®'/clear'Ê∏ÖÁêÜÂπ∂ÈáçÊñ∞Á≤òË¥¥„ÄÇ"
        ),
        "phase1_processing_sources": "Èò∂ÊÆµ 1: Ê≠£Âú®Â§ÑÁêÜ REST/RAG/Search Ê∫ê...",
        "phase2_building_index": "Èò∂ÊÆµ 2: Ê≠£Âú®‰∏∫ÊâÄÊúâÊñá‰ª∂ÊûÑÂª∫Á¥¢Âºï...",
        "phase6_file_selection": "Èò∂ÊÆµ 6: Ê≠£Âú®Â§ÑÁêÜÊñá‰ª∂ÈÄâÊã©ÂíåÈôêÂà∂...",
        "phase7_preparing_output": "Èò∂ÊÆµ 7: Ê≠£Âú®ÂáÜÂ§áÊúÄÁªàËæìÂá∫...",
        "chat_human_as_model_instructions": (
            "\n============= Chat Â§Ñ‰∫é Human as Model Ê®°Âºè =============\n"
            "ÈóÆÈ¢òÂ∑≤Â§çÂà∂Âà∞Ââ™Ë¥¥Êùø\n"
            "ËØ∑‰ΩøÁî®WebÁâàÊú¨Ê®°ÂûãËé∑ÂèñÁ≠îÊ°à\n"
            "ÊàñËÄÖ‰ΩøÁî® /conf human_as_model:false ÂÖ≥Èó≠ËØ•Ê®°ÂºèÁõ¥Êé•Âú®ÁªàÁ´ØËé∑ÂæóÁ≠îÊ°à„ÄÇ"
            "Â∞ÜËé∑ÂæóÁ≠îÊ°àÈªèË¥¥Âà∞‰∏ãÈù¢ÁöÑËæìÂÖ•Ê°ÜÔºåÊç¢Ë°åÂêéÔºå‰ΩøÁî® '/break' ÈÄÄÂá∫Ôºå'/clear' Ê∏ÖÂ±èÔºå'/eof' Êèê‰∫§„ÄÇ"
        ),
        "code_generation_start": "Ê≠£Âú®Ëá™Âä®ÁîüÊàê‰ª£Á†Å...",
        "code_generation_complete": "{{ model_names}} ‰ª£Á†ÅÁîüÊàêÂÆåÊàêÔºåËÄóÊó∂ {{ duration }} Áßí (ÈááÊ†∑Êï∞: {{ sampling_count }}), ËæìÂÖ•tokenÊï∞: {{ input_tokens }}, ËæìÂá∫tokenÊï∞: {{ output_tokens }}, ËæìÂÖ•ÊàêÊú¨: {{ input_cost }}, ËæìÂá∫ÊàêÊú¨: {{ output_cost }}, ÈÄüÂ∫¶: {{ speed }} tokens/Áßí",
        "code_merge_start": "Ê≠£Âú®Ëá™Âä®ÂêàÂπ∂‰ª£Á†Å...",
        "code_execution_warning": "ÂèëÈÄÅÁªôÊ®°ÂûãÁöÑÂÜÖÂÆπÈïøÂ∫¶‰∏∫ {{ content_length }} tokensÔºàÊÇ®ÂèØËÉΩÊî∂ÈõÜ‰∫ÜÂ§™Â§öÊñá‰ª∂ÔºâÔºåË∂ÖËøá‰∫ÜÊúÄÂ§ßËæìÂÖ•ÈïøÂ∫¶ {{ max_length }}",
        "quick_filter_start": "{{ model_name }} ÂºÄÂßãÊü•Êâæ‰∏ä‰∏ãÊñá(quick_filter)...",
        "normal_filter_start": "{{ model_name }} ÂºÄÂßãÊü•Êâæ‰∏ä‰∏ãÊñá(normal_filter)...",
        "pylint_check_failed": "‚ö†Ô∏è Pylint Ê£ÄÊü•Â§±Ë¥•: {{ error_message }}",
        "pylint_error": "‚ùå ËøêË°å Pylint Êó∂Âá∫Èîô: {{ error_message }}",
        "begin_index_source_code": "üöÄ ÂºÄÂßã‰∏∫ {{ source_dir }} ‰∏≠ÁöÑÊ∫ê‰ª£Á†ÅÂª∫Á´ãÁ¥¢Âºï",
        "unmerged_blocks_warning": "‚ö†Ô∏è ÂèëÁé∞ {{ num_blocks }} ‰∏™Êú™ÂêàÂπ∂ÁöÑ‰ª£Á†ÅÂùóÔºåÊõ¥ÊîπÂ∞Ü‰∏ç‰ºöË¢´Â∫îÁî®„ÄÇËØ∑ÊâãÂä®Ê£ÄÊü•ÂêéÈáçËØï„ÄÇ",
        "pylint_file_check_failed": "‚ö†Ô∏è {{ file_path }} ÁöÑ Pylint Ê£ÄÊü•Â§±Ë¥•„ÄÇÊõ¥ÊîπÊú™Â∫îÁî®„ÄÇÈîôËØØ: {{ error_message }}",
        "merge_success": "‚úÖ ÊàêÂäüÂêàÂπ∂‰∫Ü {{ num_files }} ‰∏™Êñá‰ª∂‰∏≠ÁöÑÊõ¥Êîπ {{ num_changes }}/{{ total_blocks }} ‰∏™‰ª£Á†ÅÂùó„ÄÇ",
        "no_changes_made": "‚ö†Ô∏è Êú™ÂØπ‰ªª‰ΩïÊñá‰ª∂ËøõË°åÊõ¥Êîπ„ÄÇËøô‰∏™ÂéüÂõ†ÂèØËÉΩÊòØÂõ†‰∏∫codingÂáΩÊï∞ÁîüÊàêÁöÑÊñáÊú¨ÂùóÊ†ºÂºèÊúâÈóÆÈ¢òÔºåÂØºËá¥Êó†Ê≥ïÂêàÂπ∂ËøõÈ°πÁõÆ",
        "unmerged_blocks_title": "Êú™ÂêàÂπ∂‰ª£Á†ÅÂùó",
        "merged_blocks_title": "ÂêàÂπ∂ÁöÑÊõ¥Êîπ",
        "unmerged_file_path": "Êñá‰ª∂: {{file_path}}",
        "unmerged_search_block": "Search Block({{similarity}}):",
        "unmerged_replace_block": "Replace Block:",
        "unmerged_blocks_total": "Êú™ÂêàÂπ∂‰ª£Á†ÅÂùóÊï∞Èáè: {{num_blocks}}",
        "git_init_required": "‚ö†Ô∏è auto_merge ‰ªÖÈÄÇÁî®‰∫é git ‰ªìÂ∫ì„ÄÇ\n\nËØ∑Â∞ùËØïÂú®Ê∫êÁõÆÂΩï‰∏≠‰ΩøÁî® git init:\n\n```shell\ncd {{ source_dir }}\ngit init.\n```\n\nÁÑ∂ÂêéÂÜçÊ¨°ËøêË°å auto-coder„ÄÇ\nÈîôËØØ: {{ error }}",
        "quick_filter_reason": "Ëá™Âä®Ëé∑Âèñ(quick_filterÊ®°Âºè)",
        "quick_filter_too_long": "‚ö†Ô∏è Á¥¢ÂºïÊñá‰ª∂ËøáÂ§ß ({{ tokens_len }}/{{ max_tokens }})„ÄÇÊü•ËØ¢Â∞ÜË¢´ÂàÜÊàê {{ split_size }} ‰∏™ÈÉ®ÂàÜÊâßË°å„ÄÇ",
        "quick_filter_tokens_len": "üìä ÂΩìÂâçÁ¥¢ÂºïÂ§ßÂ∞è: {{ tokens_len }} tokens",
        "upsert_file": "‚úÖ Êõ¥Êñ∞Êñá‰ª∂: {{ file_path }}",
        "files_merged": "‚úÖ ÊàêÂäüÂêàÂπ∂‰∫Ü {{ total }} ‰∏™Êñá‰ª∂Âà∞È°πÁõÆ‰∏≠„ÄÇ",
        "merge_failed": "‚ùå ÂêàÂπ∂Êñá‰ª∂ {{ path }} Â§±Ë¥•: {{ error }}",
        "files_merged_total": "‚úÖ ÂêàÂπ∂‰∫Ü {{ total }} ‰∏™Êñá‰ª∂Âà∞È°πÁõÆ‰∏≠„ÄÇ",
        "ranking_skip": "Âè™Êúâ1‰∏™ÂÄôÈÄâÈ°πÔºåË∑≥ËøáÊéíÂ∫è",
        "ranking_start": "ÂºÄÂßãÂØπ {{ count }} ‰∏™ÂÄôÈÄâÈ°πËøõË°åÊéíÂ∫è,‰ΩøÁî®Ê®°Âûã {{ model_name }} ÊâìÂàÜ",
        "ranking_failed_request": "ÊéíÂ∫èËØ∑Ê±ÇÂ§±Ë¥•: {{ error }}",
        "ranking_all_failed": "ÊâÄÊúâÊéíÂ∫èËØ∑Ê±ÇÈÉΩÂ§±Ë¥•",
        "ranking_complete": "{{ model_names }} ÊéíÂ∫èÂÆåÊàêÔºåËÄóÊó∂ {{ elapsed }} ÁßíÔºåÊÄªÊäïÁ•®Êï∞: {{ total_tasks }}ÔºåÊúÄ‰Ω≥ÂÄôÈÄâÁ¥¢Âºï: {{ best_candidate }}ÔºåÂæóÂàÜ: {{ scores }}ÔºåËæìÂÖ•tokenÊï∞: {{ input_tokens }}ÔºåËæìÂá∫tokenÊï∞: {{ output_tokens }}ÔºåËæìÂÖ•ÊàêÊú¨: {{ input_cost }}, ËæìÂá∫ÊàêÊú¨: {{ output_cost }}ÔºåÈÄüÂ∫¶: {{ speed }} tokens/Áßí",
        "ranking_process_failed": "ÊéíÂ∫èËøáÁ®ãÂ§±Ë¥•: {{ error }}",
        "ranking_failed": "ÊéíÂ∫èÂ§±Ë¥•ÔºåËÄóÊó∂ {{ elapsed }} ÁßíÔºå‰ΩøÁî®ÂéüÂßãÈ°∫Â∫è",
        "stream_out_stats": "Ê®°Âûã: {{ model_name }},ÊÄªËÄóÊó∂ {{ elapsed_time }} Áßí,È¶ñtokenÊó∂Èó¥: {{ first_token_time }} Áßí, ÈÄüÂ∫¶: {{ speed }} tokens/Áßí, ËæìÂÖ•tokenÊï∞: {{ input_tokens }}, ËæìÂá∫tokenÊï∞: {{ output_tokens }}, ËæìÂÖ•ÊàêÊú¨: {{ input_cost }}, ËæìÂá∫ÊàêÊú¨: {{ output_cost }}",
        "quick_filter_stats": "{{ model_names }} Quick Filter ÂÆåÊàêËÄóÊó∂ {{ elapsed_time }} ÁßíÔºåËæìÂÖ•tokenÊï∞: {{ input_tokens }}, ËæìÂá∫tokenÊï∞: {{ output_tokens }}, ËæìÂÖ•ÊàêÊú¨: {{ input_cost }}, ËæìÂá∫ÊàêÊú¨: {{ output_cost }} ÈÄüÂ∫¶: {{ speed }} tokens/Áßí",
        "quick_filter_title": "{{ model_name }} Ê≠£Âú®ÂàÜÊûêÂ¶Ç‰ΩïÁ≠õÈÄâ‰∏ä‰∏ãÊñá...",
        "quick_filter_failed": "‚ùå Âø´ÈÄüËøáÊª§Âô®Â§±Ë¥•: {{ error }}. ",
        "estimated_chat_input_tokens": "ÂØπËØùËæìÂÖ•tokenÈ¢Ñ‰º∞‰∏∫: {{ estimated_input_tokens }}",
        "estimated_input_tokens_in_generate": "ÁîüÊàê‰ª£Á†Å({{ generate_mode }})È¢ÑËÆ°ËæìÂÖ•tokenÊï∞: {{ estimated_input_tokens_in_generate }}",        
        "model_has_access_restrictions": "{{model_name}} ÊúâËÆøÈóÆÈôêÂà∂ÔºåÊó†Ê≥ï‰ΩøÁî®ÂΩìÂâçÂäüËÉΩ",
        "auto_command_not_found": "Êú™ÊâæÂà∞Ëá™Âä®ÂëΩ‰ª§: {{command}}„ÄÇËØ∑Ê£ÄÊü•ÊÇ®ÁöÑËæìÂÖ•Âπ∂ÈáçËØï„ÄÇ",
        "auto_command_failed": "Ëá™Âä®ÂëΩ‰ª§ÊâßË°åÂ§±Ë¥•: {{error}}„ÄÇËØ∑Ê£ÄÊü•ÊÇ®ÁöÑËæìÂÖ•Âπ∂ÈáçËØï„ÄÇ",
        "command_execution_result": "{{action}} ÊâßË°åÁªìÊûú",
        "satisfied_prompt": "Â∑≤Êª°Ë∂≥ÈúÄÊ±ÇÔºåÊó†ÈúÄËøõ‰∏ÄÊ≠•Êìç‰Ωú",
        "auto_command_analyzed": "Ë¢´ÈÄâÊã©Êåá‰ª§",
        "invalid_enum_value": "ÂÄº '{{value}}' ‰∏çÂú®ÂÖÅËÆ∏ÁöÑÂÄºÂàóË°®‰∏≠ ({{allowed}})",
        "conversation_pruning_start": "‚ö†Ô∏è ÂØπËØùÈïøÂ∫¶ {{total_tokens}} tokens Ë∂ÖËøáÂÆâÂÖ®ÈòàÂÄº {{safe_zone}}ÔºåÂºÄÂßã‰øÆÂâ™ÂØπËØù„ÄÇ",
        "invalid_file_number": "‚ö†Ô∏è Êó†ÊïàÁöÑÊñá‰ª∂ÁºñÂè∑ {{file_number}}ÔºåÊÄªÊñá‰ª∂Êï∞‰∏∫ {{total_files}}",        
        "all_merge_results_failed": "‚ö†Ô∏è ÊâÄÊúâÂêàÂπ∂Â∞ùËØïÈÉΩÂ§±Ë¥•ÔºåËøîÂõûÁ¨¨‰∏Ä‰∏™ÂÄôÈÄâ",
        "only_one_merge_result_success": "‚úÖ Âè™Êúâ‰∏Ä‰∏™ÂêàÂπ∂ÁªìÊûúÊàêÂäüÔºåËøîÂõûËØ•ÂÄôÈÄâ",
        "index_export_success": "Á¥¢ÂºïÂØºÂá∫ÊàêÂäü: {{path}}",
        "index_import_success": "Á¥¢ÂºïÂØºÂÖ•ÊàêÂäü: {{path}}",
        "edits_title": "ÁºñËæëÂùó",
        "diff_blocks_title": "Â∑ÆÂºÇÂùó",
        "index_exclude_files_error": "Á¥¢ÂºïÊéíÈô§Êñá‰ª∂Êó∂Âá∫Èîô: {{error}}",
        "rank_code_modification_title": "Ê®°Âûã{{model_name}}ÂØπ‰ª£Á†ÅÊâìÂàÜ",
        "sorted_files_message": "ÈáçÊñ∞ÊéíÂ∫èÂêéÁöÑÊñá‰ª∂Ë∑ØÂæÑ:\n{% for file in files %}- {{ file }}\n{% endfor %}",
        "estimated_input_tokens_in_ranking": "ÊéíÂ∫èÈ¢ÑËÆ°ËæìÂÖ•tokenÊï∞: {{ estimated_input_tokens }}",
        "file_snippet_procesed": "Êñá‰ª∂ {{ file_path }} Â§ÑÁêÜÂêétokenÊï∞: {{ tokens }} => {{ snippet_tokens }} ÂΩìÂâçÊÄªtokenÊï∞: {{ total_tokens }}",
        "tool_ask_user": "ÊÇ®ÁöÑÂõûÂ§ç: ",
        "tool_ask_user_accept":"Êî∂Âà∞ÊÇ®ÁöÑÂõûÂ§ç",
        "auto_web_analyzing": "Ê≠£Âú®ÂàÜÊûêÁΩëÈ°µËá™Âä®Âåñ‰ªªÂä°...",
        "auto_web_analyzed": "ÁΩëÈ°µËá™Âä®Âåñ‰ªªÂä°ÂàÜÊûêÂÆåÊàê",
        "executing_web_action": "ÊâßË°åÊìç‰Ωú: {{action}} - {{description}}",
        "executing_step": "ÊâßË°åÊ≠•È™§ {{step}}: {{description}}",
        "operation_cancelled": "Êìç‰ΩúÂ∑≤ÂèñÊ∂à",
        "element_not_found": "Êú™ÊâæÂà∞ÂÖÉÁ¥†: {{element}}",
        "analyzing_results": "ÂàÜÊûêÊâßË°åÁªìÊûú...",
        "next_steps_determined": "Â∑≤Á°ÆÂÆö‰∏ã‰∏ÄÊ≠•Êìç‰Ωú",
        "max_iterations_reached": "Â∑≤ËææÂà∞ÊúÄÂ§ßËø≠‰ª£Ê¨°Êï∞ {{max_iterations}}",
        "action_verification_failed": "Êìç‰ΩúÈ™åËØÅÂ§±Ë¥•: {{action}} - {{reason}}",
        "action_succeeded": "Êìç‰ΩúÊàêÂäü: {{action}}",
        "replanned_actions": "Â∑≤ÈáçÊñ∞ËßÑÂàí {{count}} ‰∏™Êìç‰Ωú",
        "web_automation_ask_user": "ÊÇ®ÁöÑÂõûÁ≠î: ",
        "filter_mode_normal": "Ê≠£Âú®‰ΩøÁî®ÊôÆÈÄöËøáÊª§Ê®°ÂºèÂ§ÑÁêÜÁ¥¢Âºï...",
        "filter_mode_big": "Á¥¢ÂºïÊñá‰ª∂ËæÉÂ§ß ({{ tokens_len }} tokens)ÔºåÊ≠£Âú®‰ΩøÁî® big_filter Ê®°ÂºèÂ§ÑÁêÜ...",
        "filter_mode_super_big": "Á¥¢ÂºïÊñá‰ª∂ÈùûÂ∏∏Â§ß ({{ tokens_len }} tokens)ÔºåÊ≠£Âú®‰ΩøÁî® super_big_filter Ê®°ÂºèÂ§ÑÁêÜ...",
        "super_big_filter_failed": "‚ùå Ë∂ÖÂ§ßËøáÊª§Âô®Â§±Ë¥•: {{ error }}.",
        "super_big_filter_stats": "{{ model_names }} Ë∂ÖÂ§ßËøáÊª§Âô®ÂÆåÊàêËÄóÊó∂ {{ elapsed_time }} ÁßíÔºåËæìÂÖ•tokenÊï∞: {{ input_tokens }}, ËæìÂá∫tokenÊï∞: {{ output_tokens }}, ËæìÂÖ•ÊàêÊú¨: {{ input_cost }}, ËæìÂá∫ÊàêÊú¨: {{ output_cost }}, ÈÄüÂ∫¶: {{ speed }} tokens/Áßí, ÂùóÁ¥¢Âºï: {{ chunk_index }}",
        "super_big_filter_splitting": "‚ö†Ô∏è Á¥¢ÂºïÊñá‰ª∂ÊûÅÂÖ∂Â∫ûÂ§ß ({{ tokens_len }}/{{ max_tokens }})„ÄÇÊü•ËØ¢Â∞ÜË¢´ÂàÜÊàê {{ split_size }} ‰∏™ÈÉ®ÂàÜËøõË°åÂ§ÑÁêÜ„ÄÇ",
        "super_big_filter_title": "{{ model_name }} Ê≠£Âú®ÂàÜÊûêÂ¶Ç‰ΩïËøáÊª§ÊûÅÂ§ßËßÑÊ®°‰∏ä‰∏ãÊñá...",
        "mcp_server_info_error": "Ëé∑ÂèñMCPÊúçÂä°Âô®‰ø°ÊÅØÊó∂Âá∫Èîô: {{ error }}",
        "mcp_server_info_title": "Â∑≤ËøûÊé•ÁöÑMCPÊúçÂä°Âô®‰ø°ÊÅØ",
        "no_commit_file_name": "Êó†Ê≥ïËé∑Âèñcommit_idÂÖ≥ËÅîÁöÑactions ÁõÆÂΩï‰∏ãÁöÑÊñá‰ª∂Âêç: {{commit_id}}",
        "yaml_update_success": "‚úÖ ÊàêÂäüÊõ¥Êñ∞YAMLÊñá‰ª∂: {{yaml_file}}",
        "yaml_save_error": "‚ùå ‰øùÂ≠òYAMLÊñá‰ª∂Âá∫Èîô {{yaml_file}}: {{error}}",
    }}


def get_system_language():
    try:
        return locale.getdefaultlocale()[0][:2]
    except:
        return 'en'


def get_message(key):
    lang = get_system_language()
    return MESSAGES.get(lang, MESSAGES['en']).get(key, MESSAGES['en'][key])


def get_message_with_format(msg_key: str, **kwargs):
    return format_str_jinja2(get_message(msg_key), **kwargs)
