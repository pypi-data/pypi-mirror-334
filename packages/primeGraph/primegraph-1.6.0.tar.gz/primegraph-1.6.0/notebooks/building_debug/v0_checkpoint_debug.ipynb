{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../..\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "from primeGraph.buffer.factory import History, LastValue\n",
    "from primeGraph.checkpoint.storage.local_storage import LocalStorage\n",
    "from primeGraph.constants import END, START\n",
    "from primeGraph.graph.executable import Graph\n",
    "from primeGraph.models.state import GraphState\n",
    "\n",
    "\n",
    "# Define our state model\n",
    "class ProcessState(GraphState):\n",
    "    status: LastValue[str]\n",
    "    results: History[Dict[str, float]]\n",
    "\n",
    "\n",
    "# Initialize state and graph with local storage and chain_id\n",
    "chain_id = \"process_workflow_v1\"\n",
    "state = ProcessState(status=\"\", results={})\n",
    "storage = LocalStorage()\n",
    "graph = Graph(state=state, checkpoint_storage=storage, chain_id=chain_id)\n",
    "\n",
    "\n",
    "# Define processing nodes\n",
    "@graph.node()\n",
    "def initialize_process(state):\n",
    "    time.sleep(0.5)  # Simulate work\n",
    "    return {\"status\": \"initializing\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def process_data_1(state):\n",
    "    time.sleep(0.5)  # Simulate work\n",
    "    return {\"status\": \"processing_1\", \"results\": {\"accuracy\": 0.85, \"step\": 1.0}}\n",
    "\n",
    "\n",
    "@graph.node(interrupt=\"after\")\n",
    "def process_data_2(state):\n",
    "    time.sleep(0.5)  # Simulate work\n",
    "    return {\"status\": \"processing_2\", \"results\": {\"accuracy\": 0.92, \"step\": 2.0}}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def finalize(state):\n",
    "    time.sleep(0.5)  # Simulate work\n",
    "    return {\"status\": \"completed\"}\n",
    "\n",
    "\n",
    "# Create the workflow\n",
    "graph.add_edge(START, \"initialize_process\")\n",
    "graph.add_edge(\"initialize_process\", \"process_data_1\")\n",
    "graph.add_edge(\"process_data_1\", \"process_data_2\")\n",
    "graph.add_edge(\"process_data_2\", \"finalize\")\n",
    "graph.add_edge(\"finalize\", END)\n",
    "\n",
    "# Compile and execute\n",
    "graph.compile()\n",
    "graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage.list_checkpoints(chain_id)\n",
    "\n",
    "graph.checkpoint_storage.list_checkpoints(chain_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage.list_checkpoints(chain_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2 (LocalStorage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from primeGraph.buffer.factory import History\n",
    "from primeGraph.checkpoint.local_storage import LocalStorage\n",
    "from primeGraph.constants import END, START\n",
    "from primeGraph.graph.executable import Graph\n",
    "from primeGraph.models.state import GraphState\n",
    "\n",
    "\n",
    "class StateForTestWithHistory(GraphState):\n",
    "    execution_order: History[str]\n",
    "\n",
    "\n",
    "state = StateForTestWithHistory(execution_order=[])\n",
    "storage = LocalStorage()\n",
    "graph = Graph(state=state, checkpoint_storage=storage)\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def task1(state):\n",
    "    print(\"task1\")\n",
    "    time.sleep(0.5)\n",
    "    return {\"execution_order\": \"task1\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def task2(state):\n",
    "    print(\"task2\")\n",
    "    time.sleep(0.5)\n",
    "    return {\"execution_order\": \"task2\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def task3(state):\n",
    "    print(\"task3\")\n",
    "    time.sleep(1)\n",
    "    return {\"execution_order\": \"task3\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def task4(state):\n",
    "    print(\"task4\")\n",
    "    time.sleep(2)\n",
    "    print(\"task4 done\")\n",
    "\n",
    "    return {\"execution_order\": \"task4\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def task5(state):\n",
    "    print(\"task5\")\n",
    "    time.sleep(1)\n",
    "    return {\"execution_order\": \"task5\"}\n",
    "\n",
    "\n",
    "@graph.node(interrupt=\"before\")\n",
    "def task6(state):\n",
    "    print(\"task6\")\n",
    "    return {\"execution_order\": \"task6\"}\n",
    "\n",
    "\n",
    "graph.add_edge(START, \"task1\")\n",
    "graph.add_edge(\"task1\", \"task2\")\n",
    "graph.add_edge(\"task2\", \"task3\")\n",
    "graph.add_edge(\"task2\", \"task4\")\n",
    "graph.add_edge(\"task2\", \"task5\")\n",
    "graph.add_edge(\"task4\", \"task6\")\n",
    "graph.add_edge(\"task3\", \"task6\")\n",
    "graph.add_edge(\"task5\", \"task6\")\n",
    "graph.add_edge(\"task6\", END)\n",
    "graph.compile()\n",
    "\n",
    "graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print as rprint\n",
    "\n",
    "rprint(graph.detailed_execution_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print as rprint\n",
    "\n",
    "graph._convert_execution_plan()\n",
    "rprint(graph.execution_plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.state.execution_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage.list_checkpoints(graph.chain_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start a new chain just to test the load from checkpoint\n",
    "new_chain_id = graph.start()\n",
    "print(new_chain_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print as rprint\n",
    "\n",
    "rprint(storage._storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"current_chain_id\", graph.chain_id)\n",
    "print(\"saved_chain_id\", chain_id)\n",
    "graph.load_from_checkpoint(chain_id)\n",
    "print(\"after load chain_id\", graph.chain_id)\n",
    "\n",
    "graph.resume()\n",
    "assert all(\n",
    "    task in graph.state.execution_order\n",
    "    for task in [\"task1\", \"task2\", \"task3\", \"task4\", \"task5\", \"task6\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.load_from_checkpoint(chain_id)\n",
    "graph.state.execution_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.state.execution_order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 3 (PostgreSQLStorage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tiny_graph.buffer.factory import History\n",
    "from tiny_graph.checkpoint.postgresql import PostgreSQLStorage\n",
    "from tiny_graph.constants import END, START\n",
    "from tiny_graph.graph.executable import Graph\n",
    "from tiny_graph.models.state import GraphState\n",
    "\n",
    "\n",
    "class StateForTestWithHistory(GraphState):\n",
    "    execution_order: History[str]\n",
    "\n",
    "\n",
    "state = StateForTestWithHistory(execution_order=[])\n",
    "storage = PostgreSQLStorage.from_config(\n",
    "    **{\n",
    "        \"host\": \"localhost\",\n",
    "        \"port\": 5432,\n",
    "        \"user\": \"tiny_graph\",\n",
    "        \"password\": \"tiny_graph\",\n",
    "        \"database\": \"tiny_graph\",\n",
    "    }\n",
    ")\n",
    "\n",
    "assert storage.check_schema(), \"Schema is not valid\"\n",
    "\n",
    "graph = Graph(state=state, checkpoint_storage=storage)\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def task1(state):\n",
    "    print(\"task1\")\n",
    "    time.sleep(0.5)\n",
    "    return {\"execution_order\": \"task1\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def task2(state):\n",
    "    print(\"task2\")\n",
    "    time.sleep(0.5)\n",
    "    return {\"execution_order\": \"task2\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def task3(state):\n",
    "    print(\"task3\")\n",
    "    time.sleep(1)\n",
    "    return {\"execution_order\": \"task3\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def task4(state):\n",
    "    print(\"task4\")\n",
    "    time.sleep(2)\n",
    "    print(\"task4 done\")\n",
    "\n",
    "    return {\"execution_order\": \"task4\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def task5(state):\n",
    "    print(\"task5\")\n",
    "    time.sleep(1)\n",
    "    return {\"execution_order\": \"task5\"}\n",
    "\n",
    "\n",
    "@graph.node(interrupt=\"before\")\n",
    "def task6(state):\n",
    "    print(\"task6\")\n",
    "    return {\"execution_order\": \"task6\"}\n",
    "\n",
    "\n",
    "graph.add_edge(START, \"task1\")\n",
    "graph.add_edge(\"task1\", \"task2\")\n",
    "graph.add_edge(\"task2\", \"task3\")\n",
    "graph.add_edge(\"task2\", \"task4\")\n",
    "graph.add_edge(\"task2\", \"task5\")\n",
    "graph.add_edge(\"task4\", \"task6\")\n",
    "graph.add_edge(\"task3\", \"task6\")\n",
    "graph.add_edge(\"task5\", \"task6\")\n",
    "graph.add_edge(\"task6\", END)\n",
    "graph.compile()\n",
    "\n",
    "graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_id = graph.start()\n",
    "print(chain_id)\n",
    "assert all(\n",
    "    task in graph.state.execution_order\n",
    "    for task in [\"task1\", \"task2\", \"task3\", \"task4\", \"task5\"]\n",
    "), \"tasks are not in there\"\n",
    "assert len(storage.list_checkpoints(graph.chain_id)) == 4  # n + 1 due to interrupt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.state.execution_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage.list_checkpoints(graph.chain_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start a new chain just to test the load from checkpoint\n",
    "new_chain_id = graph.start()\n",
    "print(new_chain_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print as rprint\n",
    "\n",
    "rprint(storage._storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"current_chain_id\", graph.chain_id)\n",
    "print(\"saved_chain_id\", chain_id)\n",
    "graph.load_from_checkpoint(chain_id)\n",
    "print(\"after load chain_id\", graph.chain_id)\n",
    "\n",
    "graph.resume()\n",
    "assert all(\n",
    "    task in graph.state.execution_order\n",
    "    for task in [\"task1\", \"task2\", \"task3\", \"task4\", \"task5\", \"task6\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.load_from_checkpoint(chain_id)\n",
    "graph.state.execution_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.state.execution_order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outro\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from primeGraph.buffer.factory import History, LastValue\n",
    "\n",
    "from primeGraph.checkpoint.local_storage import LocalStorage\n",
    "from primeGraph.constants import END, START\n",
    "from primeGraph.graph.executable import Graph\n",
    "from primeGraph.models.state import GraphState\n",
    "\n",
    "class StateForTestWithHistory(GraphState):\n",
    "  execution_order: History[str]\n",
    "  \n",
    "storage = LocalStorage()\n",
    "\n",
    "def generate_graph():\n",
    "    state = StateForTestWithHistory(execution_order=[])\n",
    "    graph = Graph(state=state, checkpoint_storage=storage)\n",
    "\n",
    "    @graph.node()\n",
    "    def task1(state):\n",
    "        print(\"task1\")\n",
    "        return {\"execution_order\": \"task1\"}\n",
    "\n",
    "    @graph.node()\n",
    "    def task2(state):\n",
    "        print(\"task2\")\n",
    "        return {\"execution_order\": \"task2\"}\n",
    "\n",
    "    @graph.node()\n",
    "    def task3(state):\n",
    "        print(\"task3\")\n",
    "        return {\"execution_order\": \"task3\"}\n",
    "\n",
    "    @graph.node()\n",
    "    def task4(state):\n",
    "        print(\"task4\")\n",
    "\n",
    "        return {\"execution_order\": \"task4\"}\n",
    "\n",
    "    @graph.node()\n",
    "    def task5(state):\n",
    "        print(\"task5\")\n",
    "        return {\"execution_order\": \"task5\"}\n",
    "\n",
    "    @graph.node(interrupt=\"before\")\n",
    "    def task6(state):\n",
    "        print(\"task6\")\n",
    "        return {\"execution_order\": \"task6\"}\n",
    "\n",
    "    graph.add_edge(START, \"task1\")\n",
    "    graph.add_edge(\"task1\", \"task2\")\n",
    "    graph.add_edge(\"task2\", \"task3\")\n",
    "    graph.add_edge(\"task2\", \"task4\")\n",
    "    graph.add_edge(\"task2\", \"task5\")\n",
    "    graph.add_edge(\"task4\", \"task6\")\n",
    "    graph.add_edge(\"task3\", \"task6\")\n",
    "    graph.add_edge(\"task5\", \"task6\")\n",
    "    graph.add_edge(\"task6\", END)\n",
    "    graph.compile()\n",
    "\n",
    "    return graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = generate_graph()\n",
    "graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.state_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_id = await graph.start_async()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.chain_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_id = graph.start()\n",
    "assert all(\n",
    "task in graph.state.execution_order for task in [\"task1\", \"task2\", \"task3\", \"task4\", \"task5\"]\n",
    "), \"tasks are not in there\"\n",
    "assert len(storage.list_checkpoints(graph.chain_id)) == 3  # n + 1 due to interrupt\n",
    "\n",
    "# start a new chain just to test the load from checkpoint\n",
    "new_chain_id = graph.start()\n",
    "assert new_chain_id != chain_id\n",
    "\n",
    "# loading first chain state\n",
    "graph = generate_graph()\n",
    "graph.load_from_checkpoint(chain_id)\n",
    "\n",
    "# resuming execution\n",
    "graph.resume()\n",
    "assert all(\n",
    "task in graph.state.execution_order for task in [\"task1\", \"task2\", \"task3\", \"task4\", \"task5\", \"task6\"]\n",
    "), \"tasks are not in there\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.next_execution_node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non serializable object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Any, Dict\n",
    "\n",
    "import instructor\n",
    "from openai import OpenAI\n",
    "from primeGraph import END, START, Graph\n",
    "from primeGraph.buffer import History, LastValue\n",
    "from primeGraph.checkpoint.postgresql import PostgreSQLStorage\n",
    "from pydantic import BaseModel, Field\n",
    "from rich import print as rprint\n",
    "from primeGraph.models.state import GraphState\n",
    "# from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "# ENVIRONMENT = os.environ.get(\"ENVIRONMENT\", \"dev\")\n",
    "# load_dotenv(f\".env.{ENVIRONMENT}\")\n",
    "\n",
    "# NOTION_API_KEY = os.getenv(\"NOTION_API_KEY\")\n",
    "\n",
    "\n",
    "sys_prompt_extract_page = \"\"\"\n",
    "==== OVERALL GUIDANCE =====\n",
    "You are an expert using Notion API. \n",
    "\n",
    "You will be given instruction on how to fill a page in Notion. You should follow the instructions carefully.\n",
    "\n",
    "You will be working with a database and adding entries to a plan database. \n",
    "\n",
    "Keep the scope of the instructions in mind and the pages as atomic but complete as possible.\n",
    "\n",
    "\n",
    "==== GUIDELINES ON HOW TO ACT =====\n",
    "\n",
    "- Follow the isntructions very carefully\n",
    "- Make good use of the Notion API to create the page\n",
    "- Make pages rich in content but also easy to ready and find the information you need\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class NotionInsertionState(GraphState):\n",
    "    created_pages: History[Any] = Field(default_factory=list)\n",
    "    instructions: LastValue[Dict[str, Any]] = Field(default_factory=dict)\n",
    "\n",
    "\n",
    "def get_notion_insertion_graph(\n",
    "    graph_params: Dict[str, Any],\n",
    "    graph_state: NotionInsertionState,\n",
    "):\n",
    "    notion_graph = Graph(state=graph_state)\n",
    "    client = instructor.from_openai(OpenAI())\n",
    "\n",
    "    # Checking required state variables\n",
    "    if not graph_state.instructions and len(graph_state.instructions) == 0:\n",
    "        if \"instructions\" not in graph_params:\n",
    "            raise ValueError(\"Instructions of type {step_name: instruction} are required to create a new page\")\n",
    "        else:\n",
    "            graph_state.instructions = graph_params[\"instructions\"]\n",
    "\n",
    "    repeated_nodes = list(graph_state.instructions.keys())\n",
    "    number_parallel_nodes = len(repeated_nodes)\n",
    "\n",
    "    # Notion initialization\n",
    "    if \"database_id\" not in graph_params:\n",
    "        raise ValueError(\"database_id is required to create a new page\")\n",
    "    # notion_client = NotionClient(database_id=graph_params[\"database_id\"], api_key=NOTION_API_KEY)\n",
    "    # page_schema = notion_client.page_schema\n",
    "    # property_options = notion_client.stringified_property_options\n",
    "\n",
    "    @notion_graph.node()\n",
    "    def start(self, state):\n",
    "        return {}\n",
    "\n",
    "    @notion_graph.node()\n",
    "    def extract_page_data(self, state):\n",
    "        \"\"\"\n",
    "        This will be generated base on the number of pages that need to be created\n",
    "        Pages will be created in parallel\n",
    "        Based on instructions on the state, each node will have the same name of the instruction key\n",
    "        We then capture the node name and grab the specific instruction for that page\n",
    "        \"\"\"\n",
    "\n",
    "        class ExtractPageDataResponse(BaseModel):\n",
    "            notion_page: page_schema = Field(description=\"The page that you should create\")  # type: ignore\n",
    "\n",
    "        try:\n",
    "            instruction = state.instructions[self.name]\n",
    "        except KeyError:\n",
    "            raise ValueError(f\"Instruction for {self.name} not found in state.instructions\")\n",
    "\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            response_model=ExtractPageDataResponse,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": sys_prompt_extract_page},\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"\"\" Create a new page in the database based on the following instructions: {instruction}. \n",
    "                                    The database has the following properties, strictly follow them: {property_options}\"\"\",\n",
    "                },\n",
    "            ],\n",
    "        )\n",
    "        rprint(completion.notion_page)\n",
    "        rprint(state)\n",
    "\n",
    "        return {\n",
    "            \"created_pages\": completion.notion_page,\n",
    "        }\n",
    "\n",
    "    @notion_graph.node()\n",
    "    def submit_to_api(self, state):\n",
    "        for page in state.created_pages:\n",
    "            page_object = page.model_dump(exclude_none=True)\n",
    "            page_object[\"parent\"][\"database_id\"] = notion_client.database_id\n",
    "            notion_client.create_page(page_object)\n",
    "        return {}\n",
    "\n",
    "    notion_graph.add_edge(START, \"start\")\n",
    "    notion_graph.add_repeating_edge(\n",
    "        \"start\",\n",
    "        \"extract_page_data\",\n",
    "        \"submit_to_api\",\n",
    "        number_parallel_nodes,\n",
    "        parallel=True if number_parallel_nodes > 1 else False,\n",
    "        repeat_names=repeated_nodes,\n",
    "    )\n",
    "    notion_graph.add_edge(\"submit_to_api\", END)\n",
    "\n",
    "    notion_graph.compile()\n",
    "\n",
    "    return notion_graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-24 23:14:56.368 - instructor - DEBUG - Patching `client.chat.completions.create` with mode=<Mode.TOOLS: 'tool_call'>\n"
     ]
    }
   ],
   "source": [
    "graph = get_notion_insertion_graph(\n",
    "    graph_params={\"database_id\": \"1234567890\"},\n",
    "    graph_state=NotionInsertionState(instructions={\"test\": \"test\", \"test2\": \"test2\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph._get_schema(NotionInsertionState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'created_pages': <primeGraph.buffer.history.HistoryBuffer at 0x11882a450>,\n",
       " 'instructions': <primeGraph.buffer.last_value.LastValueBuffer at 0x119a18f50>}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.state_schema\n",
    "graph.buffers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
