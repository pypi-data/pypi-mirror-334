# IMPORTANT: to make proper cpu/gpu resolution you must apply poetry config installer.re-resolve false
[tool.poetry]
name = "just-semantic-search-cuda"
version = "0.3.5"
description = "Core interfaces for hybrid search implementations (CUDA version)"
authors = ["Alex Karmazin <karmazinalex@gmail.com>", "Anton Kulaga <antonkulaga@gmail.com>", "Newton Winter <isoutthere@gmail.com>"]
license = "Apache-2.0"
readme = "README.md"
packages = [{include = "just_semantic_search"}]
keywords = ["python", "llm", "gpu", "cuda", "science", "review", "hybrid search", "semantic search", "gpu", "cuda"]
classifiers = [
    "Development Status :: 3 - Alpha",
    "Intended Audience :: Developers",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: 3.12",
    "Programming Language :: Python :: 3.13",
    "Programming Language :: Python :: 3.14",
    "Operating System :: Unix",
    "Operating System :: POSIX :: Linux",
    "Operating System :: MacOS :: MacOS X",
    "Operating System :: Microsoft :: Windows",
]

[[tool.poetry.source]]
name = "torch-cpu"
url = "https://download.pytorch.org/whl/cpu"
priority = "explicit"

[[tool.poetry.source]]
name = "torch-gpu"
url = "https://download.pytorch.org/whl/cu124"
priority = "explicit"

[tool.poetry.dependencies]
python = ">=3.10,<3.15"
transformers = ">=4.49.0"
sentence-transformers = ">=3.4.1"
typer = "*"
pydantic = ">=2.10.3"
scikit-learn = ">=1.5.2"
einops = ">=0.8.0"
eliot = ">=1.17.5"
eliot-tree = ">=24.0.0"

# CPU version (default) - explicitly from CPU source
torch = { version = "2.6.0+cu124", source = "torch-gpu" }

# CUDA dependencies - completely optional
triton = { version = ">=2.3.0" }

[tool.poetry.extras]
cuda = ["triton"]

[build-system]
requires = ["poetry-core>=1.0.0", "poetry-dynamic-versioning>=1.4.1"]
build-backend = "poetry.core.masonry.api"

[tool.poetry-dynamic-versioning]
enable = false
vcs = "git"
style = "semver"
pattern = "v?(?P<base>\\d+\\.\\d+\\.\\d+)"
format-jinja = "{{base}}"