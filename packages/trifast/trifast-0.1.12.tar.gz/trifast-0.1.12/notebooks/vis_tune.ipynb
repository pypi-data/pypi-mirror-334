{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path(\"../tune/\").resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df[\"device_cap\"]\n",
    "del df[\"device_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>block_j</th>\n",
       "      <th>block_k</th>\n",
       "      <th>warp</th>\n",
       "      <th>num_stages</th>\n",
       "      <th>n</th>\n",
       "      <th>h</th>\n",
       "      <th>d</th>\n",
       "      <th>cuda_time</th>\n",
       "      <th>wall_time</th>\n",
       "      <th>dtype</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>299860</th>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>0.077824</td>\n",
       "      <td>0.097275</td>\n",
       "      <td>torch.bfloat16</td>\n",
       "      <td>fwd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319809</th>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>0.077824</td>\n",
       "      <td>0.097275</td>\n",
       "      <td>torch.bfloat16</td>\n",
       "      <td>fwd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319747</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>0.077824</td>\n",
       "      <td>0.097752</td>\n",
       "      <td>torch.bfloat16</td>\n",
       "      <td>fwd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299798</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>0.077824</td>\n",
       "      <td>0.097752</td>\n",
       "      <td>torch.bfloat16</td>\n",
       "      <td>fwd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294882</th>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.078496</td>\n",
       "      <td>0.097990</td>\n",
       "      <td>torch.bfloat16</td>\n",
       "      <td>fwd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5674</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>346.864807</td>\n",
       "      <td>347.433090</td>\n",
       "      <td>torch.bfloat16</td>\n",
       "      <td>bwd_dkvb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5676</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>363.462646</td>\n",
       "      <td>364.422321</td>\n",
       "      <td>torch.bfloat16</td>\n",
       "      <td>bwd_dkvb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5675</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>374.146057</td>\n",
       "      <td>374.810457</td>\n",
       "      <td>torch.bfloat16</td>\n",
       "      <td>bwd_dkvb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5673</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>411.280396</td>\n",
       "      <td>411.404133</td>\n",
       "      <td>torch.bfloat16</td>\n",
       "      <td>bwd_dkvb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5677</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>435.978241</td>\n",
       "      <td>436.920404</td>\n",
       "      <td>torch.bfloat16</td>\n",
       "      <td>bwd_dkvb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>435214 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        block_j  block_k  warp  num_stages     n  h   d   cuda_time  \\\n",
       "299860       16       32     2           4    32  8  32    0.077824   \n",
       "319809       16       32     2           4    32  8  32    0.077824   \n",
       "319747       16       16     2           4    32  8  32    0.077824   \n",
       "299798       16       16     2           4    32  8  32    0.077824   \n",
       "294882       16       32     8           3    32  2  32    0.078496   \n",
       "...         ...      ...   ...         ...   ... ..  ..         ...   \n",
       "5674         16       16     1           1  1024  8  64  346.864807   \n",
       "5676         16       16     1           1  1024  8  64  363.462646   \n",
       "5675         16       16     1           1  1024  8  64  374.146057   \n",
       "5673         16       16     1           1  1024  8  64  411.280396   \n",
       "5677         16       16     1           1  1024  8  64  435.978241   \n",
       "\n",
       "         wall_time           dtype    method  \n",
       "299860    0.097275  torch.bfloat16       fwd  \n",
       "319809    0.097275  torch.bfloat16       fwd  \n",
       "319747    0.097752  torch.bfloat16       fwd  \n",
       "299798    0.097752  torch.bfloat16       fwd  \n",
       "294882    0.097990  torch.bfloat16       fwd  \n",
       "...            ...             ...       ...  \n",
       "5674    347.433090  torch.bfloat16  bwd_dkvb  \n",
       "5676    364.422321  torch.bfloat16  bwd_dkvb  \n",
       "5675    374.810457  torch.bfloat16  bwd_dkvb  \n",
       "5673    411.404133  torch.bfloat16  bwd_dkvb  \n",
       "5677    436.920404  torch.bfloat16  bwd_dkvb  \n",
       "\n",
       "[435214 rows x 11 columns]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(\"wall_time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_df = df.groupby(\n",
    "    [\n",
    "        \"n\",\n",
    "        \"h\",\n",
    "        \"d\",\n",
    "        \"block_j\",\n",
    "        \"block_k\",\n",
    "        \"warp\",\n",
    "        \"num_stages\",\n",
    "        \"method\",\n",
    "        \"dtype\",\n",
    "    ]\n",
    ").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('bwd_dkvb',)\n",
      "(32,)\n",
      "                                                                 cuda_time\n",
      "n  h d  block_j block_k warp num_stages method   dtype                    \n",
      "32 1 32 16      16      8    6          bwd_dkvb torch.bfloat16   0.118566\n",
      "                64      8    4          bwd_dkvb torch.bfloat16   0.126880\n",
      "                             6          bwd_dkvb torch.bfloat16   0.127712\n",
      "                        4    6          bwd_dkvb torch.bfloat16   0.130048\n",
      "        32      16      1    4          bwd_dkvb torch.bfloat16   0.134029\n",
      "                                                                 cuda_time\n",
      "n  h d  block_j block_k warp num_stages method   dtype                    \n",
      "32 1 64 16      32      2    4          bwd_dkvb torch.bfloat16   0.110573\n",
      "        32      32      4    1          bwd_dkvb torch.bfloat16   0.122507\n",
      "        16      64      8    4          bwd_dkvb torch.bfloat16   0.124928\n",
      "                16      4    6          bwd_dkvb torch.bfloat16   0.124949\n",
      "        64      16      4    6          bwd_dkvb torch.bfloat16   0.125728\n",
      "                                                                 cuda_time\n",
      "n  h d  block_j block_k warp num_stages method   dtype                    \n",
      "32 2 32 16      32      4    3          bwd_dkvb torch.bfloat16   0.092160\n",
      "        64      16      2    1          bwd_dkvb torch.bfloat16   0.105472\n",
      "                32      8    4          bwd_dkvb torch.bfloat16   0.112981\n",
      "        16      16      1    3          bwd_dkvb torch.bfloat16   0.113920\n",
      "        32      16      8    4          bwd_dkvb torch.bfloat16   0.114016\n",
      "                                                                 cuda_time\n",
      "n  h d  block_j block_k warp num_stages method   dtype                    \n",
      "32 2 64 64      32      4    3          bwd_dkvb torch.bfloat16   0.036864\n",
      "        16      16      8    6          bwd_dkvb torch.bfloat16   0.107637\n",
      "        32      64      2    3          bwd_dkvb torch.bfloat16   0.110592\n",
      "                16      4    3          bwd_dkvb torch.bfloat16   0.111226\n",
      "                32      8    3          bwd_dkvb torch.bfloat16   0.114152\n",
      "                                                                 cuda_time\n",
      "n  h d  block_j block_k warp num_stages method   dtype                    \n",
      "32 4 32 16      64      1    6          bwd_dkvb torch.bfloat16   0.053248\n",
      "                16      4    4          bwd_dkvb torch.bfloat16   0.056320\n",
      "                             6          bwd_dkvb torch.bfloat16   0.072192\n",
      "                        8    4          bwd_dkvb torch.bfloat16   0.084592\n",
      "        32      32      2    4          bwd_dkvb torch.bfloat16   0.084992\n",
      "                                                                 cuda_time\n",
      "n  h d  block_j block_k warp num_stages method   dtype                    \n",
      "32 4 64 16      32      1    3          bwd_dkvb torch.bfloat16   0.034816\n",
      "                             4          bwd_dkvb torch.bfloat16   0.044032\n",
      "        32      16      1    6          bwd_dkvb torch.bfloat16   0.053760\n",
      "        16      32      8    6          bwd_dkvb torch.bfloat16   0.082944\n",
      "        32      16      2    4          bwd_dkvb torch.bfloat16   0.102912\n",
      "                                                                 cuda_time\n",
      "n  h d  block_j block_k warp num_stages method   dtype                    \n",
      "32 8 32 32      32      2    4          bwd_dkvb torch.bfloat16   0.043008\n",
      "        64      32      8    3          bwd_dkvb torch.bfloat16   0.071680\n",
      "        16      16      2    3          bwd_dkvb torch.bfloat16   0.102768\n",
      "                32      2    3          bwd_dkvb torch.bfloat16   0.122256\n",
      "        32      32      2    2          bwd_dkvb torch.bfloat16   0.122573\n",
      "                                                                 cuda_time\n",
      "n  h d  block_j block_k warp num_stages method   dtype                    \n",
      "32 8 64 32      32      4    4          bwd_dkvb torch.bfloat16   0.049152\n",
      "                16      2    4          bwd_dkvb torch.bfloat16   0.084480\n",
      "        16      32      4    2          bwd_dkvb torch.bfloat16   0.084992\n",
      "        32      16      2    3          bwd_dkvb torch.bfloat16   0.099477\n",
      "                        8    2          bwd_dkvb torch.bfloat16   0.099669\n",
      "(64,)\n",
      "                                                                 cuda_time\n",
      "n  h d  block_j block_k warp num_stages method   dtype                    \n",
      "64 1 32 32      16      2    2          bwd_dkvb torch.bfloat16   0.033792\n",
      "        16      32      2    2          bwd_dkvb torch.bfloat16   0.080896\n",
      "                16      2    1          bwd_dkvb torch.bfloat16   0.092608\n",
      "        32      16      1    4          bwd_dkvb torch.bfloat16   0.096608\n",
      "                        4    4          bwd_dkvb torch.bfloat16   0.107701\n",
      "                                                                 cuda_time\n",
      "n  h d  block_j block_k warp num_stages method   dtype                    \n",
      "64 1 64 16      16      8    6          bwd_dkvb torch.bfloat16   0.035808\n",
      "                64      4    3          bwd_dkvb torch.bfloat16   0.046080\n",
      "        32      32      1    3          bwd_dkvb torch.bfloat16   0.054272\n",
      "                16      8    6          bwd_dkvb torch.bfloat16   0.068608\n",
      "                        2    6          bwd_dkvb torch.bfloat16   0.078848\n",
      "                                                                 cuda_time\n",
      "n  h d  block_j block_k warp num_stages method   dtype                    \n",
      "64 2 32 32      16      2    1          bwd_dkvb torch.bfloat16   0.088064\n",
      "                32      2    3          bwd_dkvb torch.bfloat16   0.092496\n",
      "        16      64      8    2          bwd_dkvb torch.bfloat16   0.094208\n",
      "        32      32      8    2          bwd_dkvb torch.bfloat16   0.099280\n",
      "                16      8    2          bwd_dkvb torch.bfloat16   0.100213\n",
      "                                                                 cuda_time\n",
      "n  h d  block_j block_k warp num_stages method   dtype                    \n",
      "64 2 64 32      32      1    3          bwd_dkvb torch.bfloat16   0.100352\n",
      "        16      64      4    4          bwd_dkvb torch.bfloat16   0.123904\n",
      "                             3          bwd_dkvb torch.bfloat16   0.127936\n",
      "        128     32      8    2          bwd_dkvb torch.bfloat16   0.137216\n",
      "        16      16      2    1          bwd_dkvb torch.bfloat16   0.141267\n",
      "                                                                 cuda_time\n",
      "n  h d  block_j block_k warp num_stages method   dtype                    \n",
      "64 4 32 32      64      1    2          bwd_dkvb torch.bfloat16   0.133120\n",
      "        64      16      8    2          bwd_dkvb torch.bfloat16   0.148672\n",
      "        16      32      1    1          bwd_dkvb torch.bfloat16   0.162784\n",
      "                64      2    1          bwd_dkvb torch.bfloat16   0.168320\n",
      "        32      64      4    2          bwd_dkvb torch.bfloat16   0.176560\n",
      "                                                                 cuda_time\n",
      "n  h d  block_j block_k warp num_stages method   dtype                    \n",
      "64 4 64 64      16      2    1          bwd_dkvb torch.bfloat16   0.163962\n",
      "                             2          bwd_dkvb torch.bfloat16   0.170867\n",
      "        16      16      1    1          bwd_dkvb torch.bfloat16   0.193376\n",
      "                        2    3          bwd_dkvb torch.bfloat16   0.207872\n",
      "        32      16      1    3          bwd_dkvb torch.bfloat16   0.222394\n",
      "                                                                 cuda_time\n",
      "n  h d  block_j block_k warp num_stages method   dtype                    \n",
      "64 8 32 16      16      4    1          bwd_dkvb torch.bfloat16   0.170182\n",
      "                        1    2          bwd_dkvb torch.bfloat16   0.200454\n",
      "                        2    3          bwd_dkvb torch.bfloat16   0.203104\n",
      "                64      2    1          bwd_dkvb torch.bfloat16   0.203539\n",
      "                16      2    2          bwd_dkvb torch.bfloat16   0.203546\n",
      "                                                                 cuda_time\n",
      "n  h d  block_j block_k warp num_stages method   dtype                    \n",
      "64 8 64 16      16      1    2          bwd_dkvb torch.bfloat16   0.205837\n",
      "        32      16      8    3          bwd_dkvb torch.bfloat16   0.219834\n",
      "                        4    3          bwd_dkvb torch.bfloat16   0.219840\n",
      "        64      64      8    1          bwd_dkvb torch.bfloat16   0.229581\n",
      "        32      16      8    2          bwd_dkvb torch.bfloat16   0.230854\n",
      "(128,)\n",
      "                                                                  cuda_time\n",
      "n   h d  block_j block_k warp num_stages method   dtype                    \n",
      "128 1 32 16      16      4    2          bwd_dkvb torch.bfloat16   0.163494\n",
      "         64      32      4    1          bwd_dkvb torch.bfloat16   0.183501\n",
      "                 64      4    1          bwd_dkvb torch.bfloat16   0.195072\n",
      "         16      16      1    2          bwd_dkvb torch.bfloat16   0.197792\n",
      "                         4    1          bwd_dkvb torch.bfloat16   0.201478\n",
      "                                                                  cuda_time\n",
      "n   h d  block_j block_k warp num_stages method   dtype                    \n",
      "128 1 64 16      64      2    1          bwd_dkvb torch.bfloat16   0.256301\n",
      "                         4    2          bwd_dkvb torch.bfloat16   0.284454\n",
      "         128     16      4    1          bwd_dkvb torch.bfloat16   0.303923\n",
      "         16      64      2    4          bwd_dkvb torch.bfloat16   0.305082\n",
      "                              2          bwd_dkvb torch.bfloat16   0.306534\n",
      "                                                                  cuda_time\n",
      "n   h d  block_j block_k warp num_stages method   dtype                    \n",
      "128 2 32 16      16      2    1          bwd_dkvb torch.bfloat16   0.244710\n",
      "                         4    4          bwd_dkvb torch.bfloat16   0.244787\n",
      "                         2    4          bwd_dkvb torch.bfloat16   0.251693\n",
      "                              2          bwd_dkvb torch.bfloat16   0.255744\n",
      "                         4    3          bwd_dkvb torch.bfloat16   0.256000\n",
      "                                                                  cuda_time\n",
      "n   h d  block_j block_k warp num_stages method   dtype                    \n",
      "128 2 64 16      32      4    3          bwd_dkvb torch.bfloat16   0.237030\n",
      "                 16      4    2          bwd_dkvb torch.bfloat16   0.240576\n",
      "                              3          bwd_dkvb torch.bfloat16   0.251942\n",
      "                 32      8    3          bwd_dkvb torch.bfloat16   0.254285\n",
      "                         4    1          bwd_dkvb torch.bfloat16   0.255514\n",
      "                                                                  cuda_time\n",
      "n   h d  block_j block_k warp num_stages method   dtype                    \n",
      "128 4 32 16      32      2    3          bwd_dkvb torch.bfloat16   0.347482\n",
      "         32      32      4    3          bwd_dkvb torch.bfloat16   0.357312\n",
      "                              1          bwd_dkvb torch.bfloat16   0.359002\n",
      "         16      32      2    2          bwd_dkvb torch.bfloat16   0.363315\n",
      "                         4    6          bwd_dkvb torch.bfloat16   0.366496\n",
      "                                                                  cuda_time\n",
      "n   h d  block_j block_k warp num_stages method   dtype                    \n",
      "128 4 64 32      32      4    3          bwd_dkvb torch.bfloat16   0.331162\n",
      "                 16      4    2          bwd_dkvb torch.bfloat16   0.360768\n",
      "         64      32      4    1          bwd_dkvb torch.bfloat16   0.361318\n",
      "         32      32      8    4          bwd_dkvb torch.bfloat16   0.365344\n",
      "                         4    2          bwd_dkvb torch.bfloat16   0.366688\n",
      "                                                                  cuda_time\n",
      "n   h d  block_j block_k warp num_stages method   dtype                    \n",
      "128 8 32 32      16      4    2          bwd_dkvb torch.bfloat16   0.470624\n",
      "                              1          bwd_dkvb torch.bfloat16   0.488026\n",
      "                         2    3          bwd_dkvb torch.bfloat16   0.492275\n",
      "         16      16      2    2          bwd_dkvb torch.bfloat16   0.497690\n",
      "                         4    2          bwd_dkvb torch.bfloat16   0.503731\n",
      "                                                                  cuda_time\n",
      "n   h d  block_j block_k warp num_stages method   dtype                    \n",
      "128 8 64 16      16      2    2          bwd_dkvb torch.bfloat16   0.546816\n",
      "                         4    3          bwd_dkvb torch.bfloat16   0.551117\n",
      "         32      32      4    2          bwd_dkvb torch.bfloat16   0.552595\n",
      "         16      16      4    2          bwd_dkvb torch.bfloat16   0.569690\n",
      "         32      32      4    3          bwd_dkvb torch.bfloat16   0.577952\n",
      "(256,)\n",
      "                                                                  cuda_time\n",
      "n   h d  block_j block_k warp num_stages method   dtype                    \n",
      "256 1 32 32      16      2    2          bwd_dkvb torch.bfloat16   0.472256\n",
      "                              3          bwd_dkvb torch.bfloat16   0.491174\n",
      "                         4    2          bwd_dkvb torch.bfloat16   0.524819\n",
      "                              4          bwd_dkvb torch.bfloat16   0.542816\n",
      "         64      16      4    2          bwd_dkvb torch.bfloat16   0.547584\n",
      "                                                                  cuda_time\n",
      "n   h d  block_j block_k warp num_stages method   dtype                    \n",
      "256 1 64 32      32      4    3          bwd_dkvb torch.bfloat16   0.501350\n",
      "         16      16      4    3          bwd_dkvb torch.bfloat16   0.545376\n",
      "                         2    3          bwd_dkvb torch.bfloat16   0.557734\n",
      "                         4    4          bwd_dkvb torch.bfloat16   0.560051\n",
      "         32      32      8    4          bwd_dkvb torch.bfloat16   0.560646\n",
      "                                                                  cuda_time\n",
      "n   h d  block_j block_k warp num_stages method   dtype                    \n",
      "256 2 32 16      16      4    3          bwd_dkvb torch.bfloat16   0.749171\n",
      "                         2    2          bwd_dkvb torch.bfloat16   0.772890\n",
      "                         4    4          bwd_dkvb torch.bfloat16   0.775878\n",
      "                         2    1          bwd_dkvb torch.bfloat16   0.800467\n",
      "                         4    2          bwd_dkvb torch.bfloat16   0.803219\n",
      "                                                                  cuda_time\n",
      "n   h d  block_j block_k warp num_stages method   dtype                    \n",
      "256 2 64 32      32      4    3          bwd_dkvb torch.bfloat16   0.938669\n",
      "         16      16      4    3          bwd_dkvb torch.bfloat16   0.951226\n",
      "                         2    2          bwd_dkvb torch.bfloat16   0.955475\n",
      "         32      32      4    2          bwd_dkvb torch.bfloat16   0.957440\n",
      "         16      16      4    2          bwd_dkvb torch.bfloat16   0.971085\n",
      "                                                                  cuda_time\n",
      "n   h d  block_j block_k warp num_stages method   dtype                    \n",
      "256 4 32 16      16      4    3          bwd_dkvb torch.bfloat16   1.400518\n",
      "                              4          bwd_dkvb torch.bfloat16   1.439021\n",
      "                         2    3          bwd_dkvb torch.bfloat16   1.440358\n",
      "                         4    1          bwd_dkvb torch.bfloat16   1.446637\n",
      "                         2    2          bwd_dkvb torch.bfloat16   1.450221\n",
      "                                                                  cuda_time\n",
      "n   h d  block_j block_k warp num_stages method   dtype                    \n",
      "256 4 64 32      32      4    3          bwd_dkvb torch.bfloat16   1.652717\n",
      "                              2          bwd_dkvb torch.bfloat16   1.657798\n",
      "                              1          bwd_dkvb torch.bfloat16   1.700211\n",
      "         16      16      2    2          bwd_dkvb torch.bfloat16   1.704083\n",
      "         32      16      2    2          bwd_dkvb torch.bfloat16   1.776774\n",
      "                                                                  cuda_time\n",
      "n   h d  block_j block_k warp num_stages method   dtype                    \n",
      "256 8 32 16      16      2    2          bwd_dkvb torch.bfloat16   2.889331\n",
      "                              1          bwd_dkvb torch.bfloat16   2.889696\n",
      "                              3          bwd_dkvb torch.bfloat16   2.909760\n",
      "         32      16      2    1          bwd_dkvb torch.bfloat16   2.927430\n",
      "                              2          bwd_dkvb torch.bfloat16   2.975296\n",
      "                                                                  cuda_time\n",
      "n   h d  block_j block_k warp num_stages method   dtype                    \n",
      "256 8 64 16      32      4    2          bwd_dkvb torch.bfloat16   3.229856\n",
      "                              3          bwd_dkvb torch.bfloat16   3.330835\n",
      "                              1          bwd_dkvb torch.bfloat16   3.404333\n",
      "         32      32      4    2          bwd_dkvb torch.bfloat16   3.430904\n",
      "                              1          bwd_dkvb torch.bfloat16   3.485168\n",
      "(512,)\n",
      "                                                                  cuda_time\n",
      "n   h d  block_j block_k warp num_stages method   dtype                    \n",
      "512 1 32 16      16      4    3          bwd_dkvb torch.bfloat16   2.872339\n",
      "                              4          bwd_dkvb torch.bfloat16   2.942682\n",
      "         32      16      2    1          bwd_dkvb torch.bfloat16   2.955206\n",
      "                              2          bwd_dkvb torch.bfloat16   3.043923\n",
      "         16      16      2    3          bwd_dkvb torch.bfloat16   3.061562\n",
      "                                                                  cuda_time\n",
      "n   h d  block_j block_k warp num_stages method   dtype                    \n",
      "512 1 64 16      32      4    3          bwd_dkvb torch.bfloat16   2.989376\n",
      "                              2          bwd_dkvb torch.bfloat16   3.199750\n",
      "                              1          bwd_dkvb torch.bfloat16   3.298613\n",
      "         32      32      4    2          bwd_dkvb torch.bfloat16   3.313568\n",
      "                              1          bwd_dkvb torch.bfloat16   3.347797\n",
      "                                                                  cuda_time\n",
      "n   h d  block_j block_k warp num_stages method   dtype                    \n",
      "512 2 32 32      16      2    1          bwd_dkvb torch.bfloat16   5.712088\n",
      "                              2          bwd_dkvb torch.bfloat16   5.740416\n",
      "         16      16      4    4          bwd_dkvb torch.bfloat16   5.916160\n",
      "                              1          bwd_dkvb torch.bfloat16   5.936128\n",
      "                         2    1          bwd_dkvb torch.bfloat16   5.958086\n",
      "                                                                  cuda_time\n",
      "n   h d  block_j block_k warp num_stages method   dtype                    \n",
      "512 2 64 16      32      4    3          bwd_dkvb torch.bfloat16   6.908504\n",
      "                 16      2    2          bwd_dkvb torch.bfloat16   7.050086\n",
      "                 32      4    1          bwd_dkvb torch.bfloat16   7.138797\n",
      "         32      32      4    1          bwd_dkvb torch.bfloat16   7.193766\n",
      "         16      16      2    1          bwd_dkvb torch.bfloat16   7.387930\n",
      "                                                                  cuda_time\n",
      "n   h d  block_j block_k warp num_stages method   dtype                    \n",
      "512 4 32 16      16      2    3          bwd_dkvb torch.bfloat16  10.926080\n",
      "                              2          bwd_dkvb torch.bfloat16  11.167669\n",
      "         32      16      2    1          bwd_dkvb torch.bfloat16  11.314176\n",
      "         16      16      2    1          bwd_dkvb torch.bfloat16  11.529722\n",
      "                 32      2    1          bwd_dkvb torch.bfloat16  12.068544\n",
      "                                                                  cuda_time\n",
      "n   h d  block_j block_k warp num_stages method   dtype                    \n",
      "512 4 64 16      32      4    3          bwd_dkvb torch.bfloat16  13.199288\n",
      "                              2          bwd_dkvb torch.bfloat16  13.670379\n",
      "                              1          bwd_dkvb torch.bfloat16  14.114944\n",
      "                 16      2    2          bwd_dkvb torch.bfloat16  14.851680\n",
      "                              1          bwd_dkvb torch.bfloat16  15.768864\n",
      "                                                                  cuda_time\n",
      "n   h d  block_j block_k warp num_stages method   dtype                    \n",
      "512 8 32 16      16      2    3          bwd_dkvb torch.bfloat16  24.043027\n",
      "                         4    3          bwd_dkvb torch.bfloat16  24.050704\n",
      "                              2          bwd_dkvb torch.bfloat16  24.418304\n",
      "                         2    2          bwd_dkvb torch.bfloat16  24.755504\n",
      "                         1    2          bwd_dkvb torch.bfloat16  25.049901\n",
      "                                                                  cuda_time\n",
      "n   h d  block_j block_k warp num_stages method   dtype                    \n",
      "512 8 64 16      32      4    3          bwd_dkvb torch.bfloat16  26.889817\n",
      "                              2          bwd_dkvb torch.bfloat16  27.656276\n",
      "                              1          bwd_dkvb torch.bfloat16  28.710899\n",
      "                 16      2    2          bwd_dkvb torch.bfloat16  31.697747\n",
      "                              1          bwd_dkvb torch.bfloat16  33.323731\n",
      "(1024,)\n",
      "                                                                   cuda_time\n",
      "n    h d  block_j block_k warp num_stages method   dtype                    \n",
      "1024 1 32 16      16      4    3          bwd_dkvb torch.bfloat16  25.503304\n",
      "                               1          bwd_dkvb torch.bfloat16  25.810544\n",
      "                          2    3          bwd_dkvb torch.bfloat16  26.288519\n",
      "                          4    2          bwd_dkvb torch.bfloat16  26.448848\n",
      "                          2    2          bwd_dkvb torch.bfloat16  27.086234\n",
      "                                                                   cuda_time\n",
      "n    h d  block_j block_k warp num_stages method   dtype                    \n",
      "1024 1 64 16      32      4    3          bwd_dkvb torch.bfloat16  30.086912\n",
      "                               2          bwd_dkvb torch.bfloat16  30.902900\n",
      "                               1          bwd_dkvb torch.bfloat16  31.498650\n",
      "                  16      2    2          bwd_dkvb torch.bfloat16  34.451520\n",
      "                          4    3          bwd_dkvb torch.bfloat16  34.855072\n",
      "                                                                   cuda_time\n",
      "n    h d  block_j block_k warp num_stages method   dtype                    \n",
      "1024 2 32 16      16      2    2          bwd_dkvb torch.bfloat16  52.133423\n",
      "                          4    1          bwd_dkvb torch.bfloat16  52.910598\n",
      "                          2    1          bwd_dkvb torch.bfloat16  53.414478\n",
      "                          1    2          bwd_dkvb torch.bfloat16  57.479455\n",
      "                               1          bwd_dkvb torch.bfloat16  63.142312\n",
      "                                                                   cuda_time\n",
      "n    h d  block_j block_k warp num_stages method   dtype                    \n",
      "1024 2 64 16      32      4    3          bwd_dkvb torch.bfloat16  59.840569\n",
      "                               2          bwd_dkvb torch.bfloat16  61.449600\n",
      "                               1          bwd_dkvb torch.bfloat16  64.741018\n",
      "                  16      2    2          bwd_dkvb torch.bfloat16  69.179744\n",
      "                               1          bwd_dkvb torch.bfloat16  72.784282\n",
      "                                                                    cuda_time\n",
      "n    h d  block_j block_k warp num_stages method   dtype                     \n",
      "1024 4 32 16      16      2    3          bwd_dkvb torch.bfloat16  104.927264\n",
      "                               2          bwd_dkvb torch.bfloat16  108.388103\n",
      "                               1          bwd_dkvb torch.bfloat16  113.951328\n",
      "                          1    2          bwd_dkvb torch.bfloat16  123.548767\n",
      "                               1          bwd_dkvb torch.bfloat16  125.320685\n",
      "                                                                    cuda_time\n",
      "n    h d  block_j block_k warp num_stages method   dtype                     \n",
      "1024 4 64 16      32      4    3          bwd_dkvb torch.bfloat16  121.958984\n",
      "                               2          bwd_dkvb torch.bfloat16  124.050119\n",
      "                               1          bwd_dkvb torch.bfloat16  129.736511\n",
      "                  16      2    2          bwd_dkvb torch.bfloat16  136.551886\n",
      "                               1          bwd_dkvb torch.bfloat16  152.328217\n",
      "                                                                    cuda_time\n",
      "n    h d  block_j block_k warp num_stages method   dtype                     \n",
      "1024 8 32 16      16      2    3          bwd_dkvb torch.bfloat16  211.926358\n",
      "                               2          bwd_dkvb torch.bfloat16  216.958301\n",
      "                               1          bwd_dkvb torch.bfloat16  227.360344\n",
      "                          1    1          bwd_dkvb torch.bfloat16  268.230057\n",
      "                                                                    cuda_time\n",
      "n    h d  block_j block_k warp num_stages method   dtype                     \n",
      "1024 8 64 16      32      4    3          bwd_dkvb torch.bfloat16  242.105949\n",
      "                               2          bwd_dkvb torch.bfloat16  243.785980\n",
      "                               1          bwd_dkvb torch.bfloat16  254.116631\n",
      "                  16      2    2          bwd_dkvb torch.bfloat16  275.990295\n",
      "                               1          bwd_dkvb torch.bfloat16  300.453247\n",
      "('bwd_dq',)\n",
      "(32,)\n",
      "                                                               cuda_time\n",
      "n  h d  block_j block_k warp num_stages method dtype                    \n",
      "32 1 32 32      64      1    3          bwd_dq torch.bfloat16   0.082635\n",
      "                128     4    4          bwd_dq torch.bfloat16   0.086490\n",
      "        64      16      2    1          bwd_dq torch.bfloat16   0.086912\n",
      "                64      8    3          bwd_dq torch.bfloat16   0.088218\n",
      "        16      32      8    3          bwd_dq torch.bfloat16   0.088683\n",
      "                                                               cuda_time\n",
      "n  h d  block_j block_k warp num_stages method dtype                    \n",
      "32 1 64 16      16      4    6          bwd_dq torch.bfloat16   0.078475\n",
      "        32      32      1    1          bwd_dq torch.bfloat16   0.084632\n",
      "        128     64      8    2          bwd_dq torch.bfloat16   0.092779\n",
      "        16      16      1    4          bwd_dq torch.bfloat16   0.096960\n",
      "        32      16      4    3          bwd_dq torch.bfloat16   0.097968\n",
      "                                                               cuda_time\n",
      "n  h d  block_j block_k warp num_stages method dtype                    \n",
      "32 2 32 128     32      4    4          bwd_dq torch.bfloat16   0.090741\n",
      "        16      16      1    4          bwd_dq torch.bfloat16   0.092480\n",
      "        64      16      2    3          bwd_dq torch.bfloat16   0.093424\n",
      "        32      16      2    1          bwd_dq torch.bfloat16   0.094112\n",
      "        16      16      2    2          bwd_dq torch.bfloat16   0.094880\n",
      "                                                               cuda_time\n",
      "n  h d  block_j block_k warp num_stages method dtype                    \n",
      "32 2 64 32      64      4    4          bwd_dq torch.bfloat16   0.048384\n",
      "        16      32      1    1          bwd_dq torch.bfloat16   0.061488\n",
      "        32      32      4    2          bwd_dq torch.bfloat16   0.090280\n",
      "        128     32      8    1          bwd_dq torch.bfloat16   0.094816\n",
      "        32      64      4    3          bwd_dq torch.bfloat16   0.096256\n",
      "                                                               cuda_time\n",
      "n  h d  block_j block_k warp num_stages method dtype                    \n",
      "32 4 32 32      32      2    4          bwd_dq torch.bfloat16   0.077760\n",
      "        64      64      8    2          bwd_dq torch.bfloat16   0.080949\n",
      "        16      16      4    2          bwd_dq torch.bfloat16   0.081224\n",
      "                64      2    4          bwd_dq torch.bfloat16   0.081944\n",
      "        32      16      1    2          bwd_dq torch.bfloat16   0.084416\n",
      "                                                               cuda_time\n",
      "n  h d  block_j block_k warp num_stages method dtype                    \n",
      "32 4 64 32      16      4    3          bwd_dq torch.bfloat16   0.080648\n",
      "                32      8    4          bwd_dq torch.bfloat16   0.083488\n",
      "        16      16      2    2          bwd_dq torch.bfloat16   0.083840\n",
      "        32      64      8    1          bwd_dq torch.bfloat16   0.084744\n",
      "        64      64      4    2          bwd_dq torch.bfloat16   0.087040\n",
      "                                                               cuda_time\n",
      "n  h d  block_j block_k warp num_stages method dtype                    \n",
      "32 8 32 32      32      4    6          bwd_dq torch.bfloat16   0.049152\n",
      "                        8    3          bwd_dq torch.bfloat16   0.081024\n",
      "                        4    2          bwd_dq torch.bfloat16   0.081685\n",
      "        64      16      1    2          bwd_dq torch.bfloat16   0.082816\n",
      "        16      32      2    4          bwd_dq torch.bfloat16   0.086736\n",
      "                                                               cuda_time\n",
      "n  h d  block_j block_k warp num_stages method dtype                    \n",
      "32 8 64 16      16      4    4          bwd_dq torch.bfloat16   0.077312\n",
      "                32      2    6          bwd_dq torch.bfloat16   0.082944\n",
      "        32      32      2    1          bwd_dq torch.bfloat16   0.090475\n",
      "                        8    1          bwd_dq torch.bfloat16   0.091104\n",
      "                        1    2          bwd_dq torch.bfloat16   0.099328\n",
      "(64,)\n",
      "                                                               cuda_time\n",
      "n  h d  block_j block_k warp num_stages method dtype                    \n",
      "64 1 32 64      64      4    1          bwd_dq torch.bfloat16   0.024576\n",
      "        128     32      8    6          bwd_dq torch.bfloat16   0.076160\n",
      "        32      16      8    1          bwd_dq torch.bfloat16   0.087808\n",
      "        64      64      1    1          bwd_dq torch.bfloat16   0.090272\n",
      "        16      128     8    1          bwd_dq torch.bfloat16   0.090824\n",
      "                                                               cuda_time\n",
      "n  h d  block_j block_k warp num_stages method dtype                    \n",
      "64 1 64 128     16      4    6          bwd_dq torch.bfloat16   0.079872\n",
      "        64      32      4    1          bwd_dq torch.bfloat16   0.089928\n",
      "        32      16      2    3          bwd_dq torch.bfloat16   0.101376\n",
      "        16      16      1    4          bwd_dq torch.bfloat16   0.103264\n",
      "                64      8    2          bwd_dq torch.bfloat16   0.103443\n",
      "                                                               cuda_time\n",
      "n  h d  block_j block_k warp num_stages method dtype                    \n",
      "64 2 32 64      128     8    1          bwd_dq torch.bfloat16   0.066912\n",
      "        16      16      4    1          bwd_dq torch.bfloat16   0.072704\n",
      "        64      16      2    4          bwd_dq torch.bfloat16   0.077360\n",
      "        16      128     4    4          bwd_dq torch.bfloat16   0.080000\n",
      "        128     32      2    1          bwd_dq torch.bfloat16   0.097280\n",
      "                                                               cuda_time\n",
      "n  h d  block_j block_k warp num_stages method dtype                    \n",
      "64 2 64 16      16      8    1          bwd_dq torch.bfloat16   0.041984\n",
      "        64      16      1    6          bwd_dq torch.bfloat16   0.050176\n",
      "        16      32      2    3          bwd_dq torch.bfloat16   0.057344\n",
      "                        4    3          bwd_dq torch.bfloat16   0.068608\n",
      "        32      32      1    3          bwd_dq torch.bfloat16   0.081920\n",
      "                                                               cuda_time\n",
      "n  h d  block_j block_k warp num_stages method dtype                    \n",
      "64 4 32 128     64      4    1          bwd_dq torch.bfloat16   0.027648\n",
      "        64      64      1    1          bwd_dq torch.bfloat16   0.029696\n",
      "        16      16      4    6          bwd_dq torch.bfloat16   0.038912\n",
      "        64      32      2    3          bwd_dq torch.bfloat16   0.040960\n",
      "        128     64      4    4          bwd_dq torch.bfloat16   0.043008\n",
      "                                                               cuda_time\n",
      "n  h d  block_j block_k warp num_stages method dtype                    \n",
      "64 4 64 16      32      2    3          bwd_dq torch.bfloat16   0.046080\n",
      "                        8    4          bwd_dq torch.bfloat16   0.058368\n",
      "        32      128     4    2          bwd_dq torch.bfloat16   0.059392\n",
      "        128     32      4    4          bwd_dq torch.bfloat16   0.059392\n",
      "        16      32      4    4          bwd_dq torch.bfloat16   0.067584\n",
      "                                                               cuda_time\n",
      "n  h d  block_j block_k warp num_stages method dtype                    \n",
      "64 8 32 64      64      4    2          bwd_dq torch.bfloat16   0.044032\n",
      "        16      16      2    2          bwd_dq torch.bfloat16   0.053248\n",
      "        32      64      1    2          bwd_dq torch.bfloat16   0.065536\n",
      "                32      8    4          bwd_dq torch.bfloat16   0.066560\n",
      "        16      32      4    4          bwd_dq torch.bfloat16   0.066560\n",
      "                                                               cuda_time\n",
      "n  h d  block_j block_k warp num_stages method dtype                    \n",
      "64 8 64 16      32      2    2          bwd_dq torch.bfloat16   0.117075\n",
      "        64      32      2    2          bwd_dq torch.bfloat16   0.123219\n",
      "        16      16      2    6          bwd_dq torch.bfloat16   0.124493\n",
      "        32      16      2    4          bwd_dq torch.bfloat16   0.128243\n",
      "        64      32      4    1          bwd_dq torch.bfloat16   0.132032\n",
      "(128,)\n",
      "                                                                cuda_time\n",
      "n   h d  block_j block_k warp num_stages method dtype                    \n",
      "128 1 32 16      16      4    2          bwd_dq torch.bfloat16   0.036832\n",
      "         128     32      4    4          bwd_dq torch.bfloat16   0.043008\n",
      "                 16      1    1          bwd_dq torch.bfloat16   0.048000\n",
      "         64      64      8    3          bwd_dq torch.bfloat16   0.054272\n",
      "                 32      2    1          bwd_dq torch.bfloat16   0.074240\n",
      "                                                                cuda_time\n",
      "n   h d  block_j block_k warp num_stages method dtype                    \n",
      "128 1 64 32      32      2    4          bwd_dq torch.bfloat16   0.057344\n",
      "         64      16      4    2          bwd_dq torch.bfloat16   0.102795\n",
      "         128     32      4    1          bwd_dq torch.bfloat16   0.104075\n",
      "         32      128     8    1          bwd_dq torch.bfloat16   0.104800\n",
      "         128     16      4    1          bwd_dq torch.bfloat16   0.104875\n",
      "                                                                cuda_time\n",
      "n   h d  block_j block_k warp num_stages method dtype                    \n",
      "128 2 32 64      16      4    2          bwd_dq torch.bfloat16   0.112358\n",
      "                 64      2    1          bwd_dq torch.bfloat16   0.116307\n",
      "         16      16      1    1          bwd_dq torch.bfloat16   0.117146\n",
      "         32      32      1    3          bwd_dq torch.bfloat16   0.117318\n",
      "         16      64      1    1          bwd_dq torch.bfloat16   0.117747\n",
      "                                                                cuda_time\n",
      "n   h d  block_j block_k warp num_stages method dtype                    \n",
      "128 2 64 64      128     4    1          bwd_dq torch.bfloat16   0.099328\n",
      "         128     64      8    2          bwd_dq torch.bfloat16   0.101376\n",
      "         32      32      4    1          bwd_dq torch.bfloat16   0.134886\n",
      "         64      32      4    1          bwd_dq torch.bfloat16   0.135072\n",
      "         128     64      8    1          bwd_dq torch.bfloat16   0.143360\n",
      "                                                                cuda_time\n",
      "n   h d  block_j block_k warp num_stages method dtype                    \n",
      "128 4 32 32      32      2    3          bwd_dq torch.bfloat16   0.134541\n",
      "         128     16      4    2          bwd_dq torch.bfloat16   0.136339\n",
      "         32      16      2    1          bwd_dq torch.bfloat16   0.136544\n",
      "         64      16      4    6          bwd_dq torch.bfloat16   0.138035\n",
      "         128     16      4    1          bwd_dq torch.bfloat16   0.142938\n",
      "                                                                cuda_time\n",
      "n   h d  block_j block_k warp num_stages method dtype                    \n",
      "128 4 64 64      16      4    1          bwd_dq torch.bfloat16   0.182003\n",
      "         32      32      4    1          bwd_dq torch.bfloat16   0.190118\n",
      "         64      32      4    1          bwd_dq torch.bfloat16   0.195392\n",
      "                 16      4    2          bwd_dq torch.bfloat16   0.199219\n",
      "         128     16      4    1          bwd_dq torch.bfloat16   0.202477\n",
      "                                                                cuda_time\n",
      "n   h d  block_j block_k warp num_stages method dtype                    \n",
      "128 8 32 16      32      1    2          bwd_dq torch.bfloat16   0.194829\n",
      "         32      32      2    1          bwd_dq torch.bfloat16   0.196570\n",
      "                 16      2    3          bwd_dq torch.bfloat16   0.202854\n",
      "         128     16      4    6          bwd_dq torch.bfloat16   0.203085\n",
      "         64      32      2    3          bwd_dq torch.bfloat16   0.203520\n",
      "                                                                cuda_time\n",
      "n   h d  block_j block_k warp num_stages method dtype                    \n",
      "128 8 64 32      16      2    3          bwd_dq torch.bfloat16   0.253485\n",
      "         128     32      4    1          bwd_dq torch.bfloat16   0.254995\n",
      "         32      64      4    1          bwd_dq torch.bfloat16   0.258048\n",
      "                 32      2    1          bwd_dq torch.bfloat16   0.263149\n",
      "                 16      1    1          bwd_dq torch.bfloat16   0.265171\n",
      "(256,)\n",
      "                                                                cuda_time\n",
      "n   h d  block_j block_k warp num_stages method dtype                    \n",
      "256 1 32 64      32      4    3          bwd_dq torch.bfloat16   0.173523\n",
      "         32      32      2    3          bwd_dq torch.bfloat16   0.188211\n",
      "         16      32      2    2          bwd_dq torch.bfloat16   0.189638\n",
      "         128     16      4    3          bwd_dq torch.bfloat16   0.190848\n",
      "         32      32      1    3          bwd_dq torch.bfloat16   0.191462\n",
      "                                                                cuda_time\n",
      "n   h d  block_j block_k warp num_stages method dtype                    \n",
      "256 1 64 64      32      4    1          bwd_dq torch.bfloat16   0.216813\n",
      "                 16      2    1          bwd_dq torch.bfloat16   0.264320\n",
      "                              3          bwd_dq torch.bfloat16   0.264582\n",
      "                 32      2    2          bwd_dq torch.bfloat16   0.266445\n",
      "                 16      4    2          bwd_dq torch.bfloat16   0.268045\n",
      "                                                                cuda_time\n",
      "n   h d  block_j block_k warp num_stages method dtype                    \n",
      "256 2 32 64      16      2    3          bwd_dq torch.bfloat16   0.228090\n",
      "         32      16      2    1          bwd_dq torch.bfloat16   0.233062\n",
      "         64      16      4    1          bwd_dq torch.bfloat16   0.234208\n",
      "                         2    4          bwd_dq torch.bfloat16   0.244294\n",
      "         32      16      2    2          bwd_dq torch.bfloat16   0.247021\n",
      "                                                                cuda_time\n",
      "n   h d  block_j block_k warp num_stages method dtype                    \n",
      "256 2 64 64      32      4    1          bwd_dq torch.bfloat16   0.306701\n",
      "                         2    1          bwd_dq torch.bfloat16   0.360218\n",
      "                 64      4    1          bwd_dq torch.bfloat16   0.364800\n",
      "                 16      4    3          bwd_dq torch.bfloat16   0.370074\n",
      "         128     16      8    1          bwd_dq torch.bfloat16   0.371098\n",
      "                                                                cuda_time\n",
      "n   h d  block_j block_k warp num_stages method dtype                    \n",
      "256 4 32 64      32      4    2          bwd_dq torch.bfloat16   0.334643\n",
      "                              1          bwd_dq torch.bfloat16   0.342598\n",
      "                 16      4    3          bwd_dq torch.bfloat16   0.343034\n",
      "         32      32      2    1          bwd_dq torch.bfloat16   0.353082\n",
      "         64      32      2    1          bwd_dq torch.bfloat16   0.353894\n",
      "                                                                cuda_time\n",
      "n   h d  block_j block_k warp num_stages method dtype                    \n",
      "256 4 64 64      64      4    1          bwd_dq torch.bfloat16   0.550022\n",
      "                 32      4    1          bwd_dq torch.bfloat16   0.558899\n",
      "         128     32      4    1          bwd_dq torch.bfloat16   0.571258\n",
      "                 16      4    1          bwd_dq torch.bfloat16   0.581798\n",
      "         32      32      4    1          bwd_dq torch.bfloat16   0.584038\n",
      "                                                                cuda_time\n",
      "n   h d  block_j block_k warp num_stages method dtype                    \n",
      "256 8 32 64      32      4    1          bwd_dq torch.bfloat16   0.571302\n",
      "                              2          bwd_dq torch.bfloat16   0.576288\n",
      "                 16      2    1          bwd_dq torch.bfloat16   0.578765\n",
      "         32      32      2    1          bwd_dq torch.bfloat16   0.591456\n",
      "                 64      2    1          bwd_dq torch.bfloat16   0.593800\n",
      "                                                                cuda_time\n",
      "n   h d  block_j block_k warp num_stages method dtype                    \n",
      "256 8 64 64      32      4    1          bwd_dq torch.bfloat16   0.988992\n",
      "         128     32      4    1          bwd_dq torch.bfloat16   1.024256\n",
      "         64      16      4    1          bwd_dq torch.bfloat16   1.101429\n",
      "         32      32      2    1          bwd_dq torch.bfloat16   1.105024\n",
      "                 64      4    1          bwd_dq torch.bfloat16   1.128704\n",
      "(512,)\n",
      "                                                                cuda_time\n",
      "n   h d  block_j block_k warp num_stages method dtype                    \n",
      "512 1 32 64      32      4    1          bwd_dq torch.bfloat16   0.553677\n",
      "                         2    1          bwd_dq torch.bfloat16   0.565190\n",
      "                         4    2          bwd_dq torch.bfloat16   0.576192\n",
      "                 64      2    1          bwd_dq torch.bfloat16   0.590061\n",
      "         32      16      2    1          bwd_dq torch.bfloat16   0.592864\n",
      "                                                                cuda_time\n",
      "n   h d  block_j block_k warp num_stages method dtype                    \n",
      "512 1 64 64      16      4    1          bwd_dq torch.bfloat16   0.954240\n",
      "         128     32      4    1          bwd_dq torch.bfloat16   1.014138\n",
      "         64      16      2    1          bwd_dq torch.bfloat16   1.044230\n",
      "                 64      4    1          bwd_dq torch.bfloat16   1.047208\n",
      "                 32      4    1          bwd_dq torch.bfloat16   1.047680\n",
      "                                                                cuda_time\n",
      "n   h d  block_j block_k warp num_stages method dtype                    \n",
      "512 2 32 128     64      4    1          bwd_dq torch.bfloat16   1.025024\n",
      "         64      64      4    1          bwd_dq torch.bfloat16   1.054726\n",
      "         32      64      2    1          bwd_dq torch.bfloat16   1.055456\n",
      "         64      32      2    1          bwd_dq torch.bfloat16   1.060352\n",
      "         128     16      4    1          bwd_dq torch.bfloat16   1.064493\n",
      "                                                                cuda_time\n",
      "n   h d  block_j block_k warp num_stages method dtype                    \n",
      "512 2 64 64      32      4    1          bwd_dq torch.bfloat16   1.745306\n",
      "         128     32      4    1          bwd_dq torch.bfloat16   1.799373\n",
      "         32      64      4    1          bwd_dq torch.bfloat16   1.880632\n",
      "         64      16      4    1          bwd_dq torch.bfloat16   1.891096\n",
      "         32      32      2    1          bwd_dq torch.bfloat16   1.908531\n",
      "                                                                cuda_time\n",
      "n   h d  block_j block_k warp num_stages method dtype                    \n",
      "512 4 32 128     32      4    1          bwd_dq torch.bfloat16   1.916090\n",
      "         64      32      2    1          bwd_dq torch.bfloat16   1.933043\n",
      "                         4    1          bwd_dq torch.bfloat16   1.956262\n",
      "         128     32      2    1          bwd_dq torch.bfloat16   1.963578\n",
      "                 64      4    1          bwd_dq torch.bfloat16   1.991955\n",
      "                                                                cuda_time\n",
      "n   h d  block_j block_k warp num_stages method dtype                    \n",
      "512 4 64 64      32      4    1          bwd_dq torch.bfloat16   3.657357\n",
      "                 64      4    1          bwd_dq torch.bfloat16   3.983701\n",
      "         32      32      2    1          bwd_dq torch.bfloat16   4.045941\n",
      "         64      32      2    1          bwd_dq torch.bfloat16   4.124416\n",
      "         32      64      4    1          bwd_dq torch.bfloat16   4.124992\n",
      "                                                                cuda_time\n",
      "n   h d  block_j block_k warp num_stages method dtype                    \n",
      "512 8 32 64      16      2    1          bwd_dq torch.bfloat16   3.911168\n",
      "         128     32      4    1          bwd_dq torch.bfloat16   3.918187\n",
      "         64      64      2    1          bwd_dq torch.bfloat16   3.984384\n",
      "                         4    1          bwd_dq torch.bfloat16   4.024691\n",
      "         32      64      2    1          bwd_dq torch.bfloat16   4.096128\n",
      "                                                                cuda_time\n",
      "n   h d  block_j block_k warp num_stages method dtype                    \n",
      "512 8 64 64      32      4    1          bwd_dq torch.bfloat16   7.900235\n",
      "         128     32      4    1          bwd_dq torch.bfloat16   8.047376\n",
      "         64      16      4    1          bwd_dq torch.bfloat16   8.361024\n",
      "                         2    1          bwd_dq torch.bfloat16   8.605472\n",
      "                 32      2    1          bwd_dq torch.bfloat16   8.685568\n",
      "(1024,)\n",
      "                                                                 cuda_time\n",
      "n    h d  block_j block_k warp num_stages method dtype                    \n",
      "1024 1 32 128     64      4    1          bwd_dq torch.bfloat16   3.691520\n",
      "                  32      4    1          bwd_dq torch.bfloat16   3.704422\n",
      "                          2    1          bwd_dq torch.bfloat16   3.822152\n",
      "          64      32      2    1          bwd_dq torch.bfloat16   3.840410\n",
      "                  64      2    1          bwd_dq torch.bfloat16   3.842539\n",
      "                                                                 cuda_time\n",
      "n    h d  block_j block_k warp num_stages method dtype                    \n",
      "1024 1 64 64      32      4    1          bwd_dq torch.bfloat16   7.176432\n",
      "                  64      4    1          bwd_dq torch.bfloat16   7.353376\n",
      "          32      32      2    1          bwd_dq torch.bfloat16   7.462912\n",
      "          64      16      4    1          bwd_dq torch.bfloat16   7.607152\n",
      "          128     32      4    1          bwd_dq torch.bfloat16   7.628107\n",
      "                                                                 cuda_time\n",
      "n    h d  block_j block_k warp num_stages method dtype                    \n",
      "1024 2 32 128     32      2    1          bwd_dq torch.bfloat16   7.764336\n",
      "          64      32      2    1          bwd_dq torch.bfloat16   7.881728\n",
      "                  64      4    1          bwd_dq torch.bfloat16   8.041824\n",
      "                  32      4    1          bwd_dq torch.bfloat16   8.054784\n",
      "                  16      2    1          bwd_dq torch.bfloat16   8.088576\n",
      "                                                                 cuda_time\n",
      "n    h d  block_j block_k warp num_stages method dtype                    \n",
      "1024 2 64 32      64      4    1          bwd_dq torch.bfloat16  15.233024\n",
      "                  32      2    1          bwd_dq torch.bfloat16  15.808512\n",
      "          64      16      4    1          bwd_dq torch.bfloat16  16.265432\n",
      "          32      16      2    1          bwd_dq torch.bfloat16  17.892351\n",
      "                          1    1          bwd_dq torch.bfloat16  19.106323\n",
      "                                                                 cuda_time\n",
      "n    h d  block_j block_k warp num_stages method dtype                    \n",
      "1024 4 32 64      32      2    1          bwd_dq torch.bfloat16  15.325184\n",
      "                          4    1          bwd_dq torch.bfloat16  16.844736\n",
      "                  16      2    1          bwd_dq torch.bfloat16  18.532352\n",
      "          32      64      2    1          bwd_dq torch.bfloat16  19.622911\n",
      "          64      16      1    1          bwd_dq torch.bfloat16  20.295551\n",
      "                                                                 cuda_time\n",
      "n    h d  block_j block_k warp num_stages method dtype                    \n",
      "1024 4 64 64      16      4    1          bwd_dq torch.bfloat16  36.076070\n",
      "          32      64      4    1          bwd_dq torch.bfloat16  37.309184\n",
      "                  16      2    1          bwd_dq torch.bfloat16  39.674353\n",
      "                          1    1          bwd_dq torch.bfloat16  42.106572\n",
      "          16      32      2    1          bwd_dq torch.bfloat16  49.138081\n",
      "                                                                 cuda_time\n",
      "n    h d  block_j block_k warp num_stages method dtype                    \n",
      "1024 8 32 128     32      2    1          bwd_dq torch.bfloat16  39.585791\n",
      "          64      16      2    1          bwd_dq torch.bfloat16  40.302489\n",
      "          32      16      2    1          bwd_dq torch.bfloat16  41.438208\n",
      "                          1    1          bwd_dq torch.bfloat16  44.699699\n",
      "          16      32      2    1          bwd_dq torch.bfloat16  58.109798\n",
      "                                                                 cuda_time\n",
      "n    h d  block_j block_k warp num_stages method dtype                    \n",
      "1024 8 64 64      32      4    1          bwd_dq torch.bfloat16  77.126656\n",
      "                  16      4    1          bwd_dq torch.bfloat16  79.676414\n",
      "          32      32      2    1          bwd_dq torch.bfloat16  81.527552\n",
      "                  16      2    1          bwd_dq torch.bfloat16  86.158333\n",
      "                          1    1          bwd_dq torch.bfloat16  86.174772\n",
      "('fwd',)\n",
      "(32,)\n",
      "                                                               cuda_time\n",
      "n  h d  block_j block_k warp num_stages method dtype                    \n",
      "32 1 32 64      64      8    2          fwd    torch.bfloat16   0.048736\n",
      "                16      4    2          fwd    torch.bfloat16   0.052112\n",
      "        16      64      4    2          fwd    torch.bfloat16   0.052736\n",
      "        32      128     2    2          fwd    torch.bfloat16   0.061120\n",
      "        64      128     4    3          fwd    torch.bfloat16   0.062976\n",
      "                                                               cuda_time\n",
      "n  h d  block_j block_k warp num_stages method dtype                    \n",
      "32 1 64 32      64      2    3          fwd    torch.bfloat16   0.059360\n",
      "        16      16      4    2          fwd    torch.bfloat16   0.063488\n",
      "                128     2    4          fwd    torch.bfloat16   0.064117\n",
      "        64      64      4    2          fwd    torch.bfloat16   0.066560\n",
      "        16      128     4    1          fwd    torch.bfloat16   0.068267\n",
      "                                                               cuda_time\n",
      "n  h d  block_j block_k warp num_stages method dtype                    \n",
      "32 2 32 16      128     1    2          fwd    torch.bfloat16   0.043008\n",
      "        128     64      2    6          fwd    torch.bfloat16   0.055328\n",
      "        32      16      8    1          fwd    torch.bfloat16   0.056880\n",
      "        128     128     8    6          fwd    torch.bfloat16   0.061152\n",
      "        64      64      4    4          fwd    torch.bfloat16   0.065536\n",
      "                                                               cuda_time\n",
      "n  h d  block_j block_k warp num_stages method dtype                    \n",
      "32 2 64 32      64      1    3          fwd    torch.bfloat16   0.049840\n",
      "        64      64      1    1          fwd    torch.bfloat16   0.054432\n",
      "                128     8    4          fwd    torch.bfloat16   0.054912\n",
      "        128     64      8    2          fwd    torch.bfloat16   0.059392\n",
      "                32      8    2          fwd    torch.bfloat16   0.060208\n",
      "                                                               cuda_time\n",
      "n  h d  block_j block_k warp num_stages method dtype                    \n",
      "32 4 32 16      64      1    4          fwd    torch.bfloat16   0.011328\n",
      "        128     64      8    2          fwd    torch.bfloat16   0.015360\n",
      "        64      128     4    4          fwd    torch.bfloat16   0.056736\n",
      "                32      8    1          fwd    torch.bfloat16   0.059051\n",
      "        128     64      4    6          fwd    torch.bfloat16   0.059904\n",
      "                                                               cuda_time\n",
      "n  h d  block_j block_k warp num_stages method dtype                    \n",
      "32 4 64 16      128     1    6          fwd    torch.bfloat16   0.016384\n",
      "        128     64      4    3          fwd    torch.bfloat16   0.037888\n",
      "        16      128     1    3          fwd    torch.bfloat16   0.046080\n",
      "        32      64      2    2          fwd    torch.bfloat16   0.054448\n",
      "        16      16      2    1          fwd    torch.bfloat16   0.060757\n",
      "                                                               cuda_time\n",
      "n  h d  block_j block_k warp num_stages method dtype                    \n",
      "32 8 32 16      16      1    3          fwd    torch.bfloat16   0.014336\n",
      "                        2    6          fwd    torch.bfloat16   0.052992\n",
      "        128     64      4    2          fwd    torch.bfloat16   0.058016\n",
      "        16      16      4    3          fwd    torch.bfloat16   0.060683\n",
      "        32      128     1    4          fwd    torch.bfloat16   0.063648\n",
      "                                                               cuda_time\n",
      "n  h d  block_j block_k warp num_stages method dtype                    \n",
      "32 8 64 128     64      4    1          fwd    torch.bfloat16   0.045056\n",
      "        16      32      8    2          fwd    torch.bfloat16   0.064512\n",
      "                16      4    6          fwd    torch.bfloat16   0.065536\n",
      "                        1    4          fwd    torch.bfloat16   0.068776\n",
      "        64      32      2    3          fwd    torch.bfloat16   0.069184\n",
      "(64,)\n",
      "                                                               cuda_time\n",
      "n  h d  block_j block_k warp num_stages method dtype                    \n",
      "64 1 32 16      16      2    6          fwd    torch.bfloat16   0.036368\n",
      "        64      32      2    2          fwd    torch.bfloat16   0.057520\n",
      "        16      16      1    1          fwd    torch.bfloat16   0.064275\n",
      "                64      4    4          fwd    torch.bfloat16   0.068072\n",
      "        128     32      4    6          fwd    torch.bfloat16   0.068520\n",
      "                                                               cuda_time\n",
      "n  h d  block_j block_k warp num_stages method dtype                    \n",
      "64 1 64 16      64      2    4          fwd    torch.bfloat16   0.057856\n",
      "        32      64      2    6          fwd    torch.bfloat16   0.058699\n",
      "        64      32      4    3          fwd    torch.bfloat16   0.062208\n",
      "        32      64      4    2          fwd    torch.bfloat16   0.062432\n",
      "                        2    1          fwd    torch.bfloat16   0.064437\n",
      "                                                               cuda_time\n",
      "n  h d  block_j block_k warp num_stages method dtype                    \n",
      "64 2 32 16      16      8    2          fwd    torch.bfloat16   0.041984\n",
      "                        2    2          fwd    torch.bfloat16   0.064853\n",
      "                64      8    3          fwd    torch.bfloat16   0.065536\n",
      "        64      64      2    4          fwd    torch.bfloat16   0.066901\n",
      "        16      32      1    3          fwd    torch.bfloat16   0.070453\n",
      "                                                               cuda_time\n",
      "n  h d  block_j block_k warp num_stages method dtype                    \n",
      "64 2 64 16      32      2    4          fwd    torch.bfloat16   0.029696\n",
      "        32      16      4    2          fwd    torch.bfloat16   0.052224\n",
      "        16      32      8    3          fwd    torch.bfloat16   0.061440\n",
      "                        2    2          fwd    torch.bfloat16   0.070600\n",
      "        32      64      2    3          fwd    torch.bfloat16   0.072480\n",
      "                                                               cuda_time\n",
      "n  h d  block_j block_k warp num_stages method dtype                    \n",
      "64 4 32 16      32      1    6          fwd    torch.bfloat16   0.022528\n",
      "                128     4    6          fwd    torch.bfloat16   0.024576\n",
      "                16      4    1          fwd    torch.bfloat16   0.031744\n",
      "                64      2    4          fwd    torch.bfloat16   0.064971\n",
      "                        1    1          fwd    torch.bfloat16   0.068992\n",
      "                                                               cuda_time\n",
      "n  h d  block_j block_k warp num_stages method dtype                    \n",
      "64 4 64 64      16      1    6          fwd    torch.bfloat16   0.040960\n",
      "                64      4    3          fwd    torch.bfloat16   0.056085\n",
      "        32      64      2    6          fwd    torch.bfloat16   0.057856\n",
      "        16      32      1    2          fwd    torch.bfloat16   0.059488\n",
      "        32      128     2    2          fwd    torch.bfloat16   0.059648\n",
      "                                                               cuda_time\n",
      "n  h d  block_j block_k warp num_stages method dtype                    \n",
      "64 8 32 32      128     2    4          fwd    torch.bfloat16   0.029696\n",
      "        128     64      8    3          fwd    torch.bfloat16   0.036864\n",
      "        16      32      2    2          fwd    torch.bfloat16   0.038912\n",
      "                128     2    2          fwd    torch.bfloat16   0.041984\n",
      "        64      16      4    2          fwd    torch.bfloat16   0.048779\n",
      "                                                               cuda_time\n",
      "n  h d  block_j block_k warp num_stages method dtype                    \n",
      "64 8 64 16      64      4    2          fwd    torch.bfloat16   0.032768\n",
      "        32      16      2    2          fwd    torch.bfloat16   0.037888\n",
      "                128     4    2          fwd    torch.bfloat16   0.037888\n",
      "                        1    2          fwd    torch.bfloat16   0.054400\n",
      "        64      32      4    6          fwd    torch.bfloat16   0.055968\n",
      "(128,)\n",
      "                                                                cuda_time\n",
      "n   h d  block_j block_k warp num_stages method dtype                    \n",
      "128 1 32 64      16      1    3          fwd    torch.bfloat16   0.027648\n",
      "                 64      2    4          fwd    torch.bfloat16   0.034816\n",
      "         32      32      8    6          fwd    torch.bfloat16   0.040960\n",
      "         16      32      2    6          fwd    torch.bfloat16   0.052224\n",
      "         64      16      4    1          fwd    torch.bfloat16   0.056320\n",
      "                                                                cuda_time\n",
      "n   h d  block_j block_k warp num_stages method dtype                    \n",
      "128 1 64 64      32      8    2          fwd    torch.bfloat16   0.053248\n",
      "         32      16      4    6          fwd    torch.bfloat16   0.072704\n",
      "                 32      2    2          fwd    torch.bfloat16   0.074968\n",
      "         64      32      4    3          fwd    torch.bfloat16   0.076304\n",
      "         16      128     2    3          fwd    torch.bfloat16   0.081280\n",
      "                                                                cuda_time\n",
      "n   h d  block_j block_k warp num_stages method dtype                    \n",
      "128 2 32 64      128     8    4          fwd    torch.bfloat16   0.062464\n",
      "                              6          fwd    torch.bfloat16   0.086016\n",
      "         128     32      8    1          fwd    torch.bfloat16   0.090088\n",
      "                         4    6          fwd    torch.bfloat16   0.091136\n",
      "                 128     8    6          fwd    torch.bfloat16   0.095200\n",
      "                                                                cuda_time\n",
      "n   h d  block_j block_k warp num_stages method dtype                    \n",
      "128 2 64 128     16      4    2          fwd    torch.bfloat16   0.080896\n",
      "         64      16      4    4          fwd    torch.bfloat16   0.101376\n",
      "         32      128     2    4          fwd    torch.bfloat16   0.105472\n",
      "         64      32      2    1          fwd    torch.bfloat16   0.109920\n",
      "         32      32      8    3          fwd    torch.bfloat16   0.112128\n",
      "                                                                cuda_time\n",
      "n   h d  block_j block_k warp num_stages method dtype                    \n",
      "128 4 32 32      32      2    2          fwd    torch.bfloat16   0.092570\n",
      "         128     32      4    2          fwd    torch.bfloat16   0.095622\n",
      "         16      128     1    4          fwd    torch.bfloat16   0.103936\n",
      "         128     32      2    1          fwd    torch.bfloat16   0.115693\n",
      "         32      32      2    1          fwd    torch.bfloat16   0.116659\n",
      "                                                                cuda_time\n",
      "n   h d  block_j block_k warp num_stages method dtype                    \n",
      "128 4 64 64      128     4    2          fwd    torch.bfloat16   0.117760\n",
      "                              4          fwd    torch.bfloat16   0.132730\n",
      "         128     64      4    1          fwd    torch.bfloat16   0.155648\n",
      "         64      128     4    1          fwd    torch.bfloat16   0.158618\n",
      "         32      32      1    2          fwd    torch.bfloat16   0.159290\n",
      "                                                                cuda_time\n",
      "n   h d  block_j block_k warp num_stages method dtype                    \n",
      "128 8 32 32      128     2    3          fwd    torch.bfloat16   0.133286\n",
      "         64      16      2    2          fwd    torch.bfloat16   0.142131\n",
      "         32      128     2    2          fwd    torch.bfloat16   0.146618\n",
      "                 32      2    1          fwd    torch.bfloat16   0.146886\n",
      "                 128     1    2          fwd    torch.bfloat16   0.148819\n",
      "                                                                cuda_time\n",
      "n   h d  block_j block_k warp num_stages method dtype                    \n",
      "128 8 64 64      16      2    2          fwd    torch.bfloat16   0.197862\n",
      "         32      32      2    2          fwd    torch.bfloat16   0.204371\n",
      "         64      64      4    2          fwd    torch.bfloat16   0.204416\n",
      "                         2    1          fwd    torch.bfloat16   0.205485\n",
      "         32      16      1    1          fwd    torch.bfloat16   0.208787\n",
      "(256,)\n",
      "                                                                cuda_time\n",
      "n   h d  block_j block_k warp num_stages method dtype                    \n",
      "256 1 32 64      16      2    3          fwd    torch.bfloat16   0.127270\n",
      "                         4    3          fwd    torch.bfloat16   0.127795\n",
      "                 64      4    1          fwd    torch.bfloat16   0.130458\n",
      "                 32      2    2          fwd    torch.bfloat16   0.131674\n",
      "         128     32      4    1          fwd    torch.bfloat16   0.132678\n",
      "                                                                cuda_time\n",
      "n   h d  block_j block_k warp num_stages method dtype                    \n",
      "256 1 64 128     16      4    3          fwd    torch.bfloat16   0.173779\n",
      "                         8    3          fwd    torch.bfloat16   0.178995\n",
      "         64      64      4    2          fwd    torch.bfloat16   0.179437\n",
      "                 128     4    1          fwd    torch.bfloat16   0.186752\n",
      "                 64      4    1          fwd    torch.bfloat16   0.190144\n",
      "                                                                cuda_time\n",
      "n   h d  block_j block_k warp num_stages method dtype                    \n",
      "256 2 32 64      16      4    2          fwd    torch.bfloat16   0.176160\n",
      "                 32      4    3          fwd    torch.bfloat16   0.178464\n",
      "                              2          fwd    torch.bfloat16   0.179552\n",
      "                 64      2    2          fwd    torch.bfloat16   0.184896\n",
      "                 16      4    4          fwd    torch.bfloat16   0.185139\n",
      "                                                                cuda_time\n",
      "n   h d  block_j block_k warp num_stages method dtype                    \n",
      "256 2 64 64      16      4    2          fwd    torch.bfloat16   0.233555\n",
      "                 32      4    2          fwd    torch.bfloat16   0.240070\n",
      "                 64      4    2          fwd    torch.bfloat16   0.245626\n",
      "                 16      4    3          fwd    torch.bfloat16   0.245990\n",
      "                 32      4    3          fwd    torch.bfloat16   0.246579\n",
      "                                                                cuda_time\n",
      "n   h d  block_j block_k warp num_stages method dtype                    \n",
      "256 4 32 32      32      2    1          fwd    torch.bfloat16   0.261050\n",
      "         128     64      8    1          fwd    torch.bfloat16   0.262554\n",
      "         64      128     4    1          fwd    torch.bfloat16   0.269856\n",
      "         128     32      8    1          fwd    torch.bfloat16   0.272755\n",
      "         32      32      2    2          fwd    torch.bfloat16   0.273638\n",
      "                                                                cuda_time\n",
      "n   h d  block_j block_k warp num_stages method dtype                    \n",
      "256 4 64 128     16      4    3          fwd    torch.bfloat16   0.377350\n",
      "         64      64      4    2          fwd    torch.bfloat16   0.398086\n",
      "                 16      4    3          fwd    torch.bfloat16   0.402477\n",
      "                 64      4    1          fwd    torch.bfloat16   0.409466\n",
      "                 16      4    2          fwd    torch.bfloat16   0.409549\n",
      "                                                                cuda_time\n",
      "n   h d  block_j block_k warp num_stages method dtype                    \n",
      "256 8 32 128     32      8    1          fwd    torch.bfloat16   0.440058\n",
      "                         4    1          fwd    torch.bfloat16   0.441357\n",
      "                              3          fwd    torch.bfloat16   0.449926\n",
      "                              2          fwd    torch.bfloat16   0.454202\n",
      "         64      16      2    3          fwd    torch.bfloat16   0.462355\n",
      "                                                                cuda_time\n",
      "n   h d  block_j block_k warp num_stages method dtype                    \n",
      "256 8 64 64      16      2    2          fwd    torch.bfloat16   0.720486\n",
      "                         4    2          fwd    torch.bfloat16   0.722874\n",
      "         128     16      4    3          fwd    torch.bfloat16   0.724915\n",
      "         64      16      4    3          fwd    torch.bfloat16   0.732659\n",
      "         128     32      8    3          fwd    torch.bfloat16   0.756966\n",
      "(512,)\n",
      "                                                                cuda_time\n",
      "n   h d  block_j block_k warp num_stages method dtype                    \n",
      "512 1 32 128     64      8    1          fwd    torch.bfloat16   0.442368\n",
      "         64      16      2    2          fwd    torch.bfloat16   0.446899\n",
      "                 128     4    1          fwd    torch.bfloat16   0.457318\n",
      "         128     32      4    3          fwd    torch.bfloat16   0.479341\n",
      "                 64      4    1          fwd    torch.bfloat16   0.481536\n",
      "                                                                cuda_time\n",
      "n   h d  block_j block_k warp num_stages method dtype                    \n",
      "512 1 64 64      16      4    2          fwd    torch.bfloat16   0.664371\n",
      "         128     32      8    3          fwd    torch.bfloat16   0.694259\n",
      "                              2          fwd    torch.bfloat16   0.706912\n",
      "         64      16      4    1          fwd    torch.bfloat16   0.707098\n",
      "         128     16      4    3          fwd    torch.bfloat16   0.712877\n",
      "                                                                cuda_time\n",
      "n   h d  block_j block_k warp num_stages method dtype                    \n",
      "512 2 32 128     32      4    1          fwd    torch.bfloat16   0.752224\n",
      "         64      32      4    2          fwd    torch.bfloat16   0.769638\n",
      "         128     32      4    2          fwd    torch.bfloat16   0.773235\n",
      "         64      16      2    3          fwd    torch.bfloat16   0.789235\n",
      "         128     32      4    3          fwd    torch.bfloat16   0.797024\n",
      "                                                                cuda_time\n",
      "n   h d  block_j block_k warp num_stages method dtype                    \n",
      "512 2 64 64      32      4    2          fwd    torch.bfloat16   1.261158\n",
      "         128     16      4    3          fwd    torch.bfloat16   1.283962\n",
      "         64      64      4    1          fwd    torch.bfloat16   1.303309\n",
      "                              2          fwd    torch.bfloat16   1.311514\n",
      "                 16      2    2          fwd    torch.bfloat16   1.317408\n",
      "                                                                cuda_time\n",
      "n   h d  block_j block_k warp num_stages method dtype                    \n",
      "512 4 32 128     32      4    2          fwd    torch.bfloat16   1.393664\n",
      "         64      64      4    1          fwd    torch.bfloat16   1.416346\n",
      "                 32      2    2          fwd    torch.bfloat16   1.445459\n",
      "         128     32      4    1          fwd    torch.bfloat16   1.465459\n",
      "                              3          fwd    torch.bfloat16   1.517242\n",
      "                                                                cuda_time\n",
      "n   h d  block_j block_k warp num_stages method dtype                    \n",
      "512 4 64 64      64      4    1          fwd    torch.bfloat16   2.626739\n",
      "         128     64      4    1          fwd    torch.bfloat16   2.630560\n",
      "         64      64      2    1          fwd    torch.bfloat16   2.690029\n",
      "                 32      2    1          fwd    torch.bfloat16   2.714579\n",
      "                 16      2    2          fwd    torch.bfloat16   2.765568\n",
      "                                                                cuda_time\n",
      "n   h d  block_j block_k warp num_stages method dtype                    \n",
      "512 8 32 128     32      4    1          fwd    torch.bfloat16   2.929562\n",
      "         64      64      4    1          fwd    torch.bfloat16   2.964032\n",
      "                              2          fwd    torch.bfloat16   3.073024\n",
      "         128     32      4    2          fwd    torch.bfloat16   3.154278\n",
      "         64      16      4    2          fwd    torch.bfloat16   3.162112\n",
      "                                                                cuda_time\n",
      "n   h d  block_j block_k warp num_stages method dtype                    \n",
      "512 8 64 128     32      4    1          fwd    torch.bfloat16   5.369216\n",
      "         64      64      4    1          fwd    torch.bfloat16   5.481904\n",
      "                         2    1          fwd    torch.bfloat16   5.561344\n",
      "         128     64      4    1          fwd    torch.bfloat16   5.566992\n",
      "         64      32      4    1          fwd    torch.bfloat16   5.571936\n",
      "(1024,)\n",
      "                                                                 cuda_time\n",
      "n    h d  block_j block_k warp num_stages method dtype                    \n",
      "1024 1 32 64      32      2    2          fwd    torch.bfloat16   2.799680\n",
      "          128     16      4    3          fwd    torch.bfloat16   2.816410\n",
      "          64      32      4    2          fwd    torch.bfloat16   2.819674\n",
      "                  16      2    3          fwd    torch.bfloat16   2.906189\n",
      "                               2          fwd    torch.bfloat16   2.959974\n",
      "                                                                 cuda_time\n",
      "n    h d  block_j block_k warp num_stages method dtype                    \n",
      "1024 1 64 64      32      4    3          fwd    torch.bfloat16   4.872397\n",
      "                               1          fwd    torch.bfloat16   5.027120\n",
      "          128     16      4    3          fwd    torch.bfloat16   5.066989\n",
      "                  32      4    1          fwd    torch.bfloat16   5.152166\n",
      "          64      16      4    3          fwd    torch.bfloat16   5.165568\n",
      "                                                                 cuda_time\n",
      "n    h d  block_j block_k warp num_stages method dtype                    \n",
      "1024 2 32 128     32      8    1          fwd    torch.bfloat16   5.493077\n",
      "          64      64      4    1          fwd    torch.bfloat16   5.562759\n",
      "          128     32      4    1          fwd    torch.bfloat16   5.637203\n",
      "                               2          fwd    torch.bfloat16   6.156277\n",
      "          64      128     4    1          fwd    torch.bfloat16   6.174144\n",
      "                                                                 cuda_time\n",
      "n    h d  block_j block_k warp num_stages method dtype                    \n",
      "1024 2 64 64      32      4    1          fwd    torch.bfloat16  10.253488\n",
      "          128     16      2    1          fwd    torch.bfloat16  10.340544\n",
      "                  64      4    1          fwd    torch.bfloat16  10.345472\n",
      "          64      64      2    1          fwd    torch.bfloat16  10.391946\n",
      "          128     32      4    1          fwd    torch.bfloat16  10.416800\n",
      "                                                                 cuda_time\n",
      "n    h d  block_j block_k warp num_stages method dtype                    \n",
      "1024 4 32 64      64      4    1          fwd    torch.bfloat16  11.533152\n",
      "          128     32      4    1          fwd    torch.bfloat16  12.146752\n",
      "          64      64      2    1          fwd    torch.bfloat16  12.504064\n",
      "                  32      2    1          fwd    torch.bfloat16  12.585920\n",
      "                          4    1          fwd    torch.bfloat16  12.680192\n",
      "                                                                 cuda_time\n",
      "n    h d  block_j block_k warp num_stages method dtype                    \n",
      "1024 4 64 64      64      4    1          fwd    torch.bfloat16  22.104353\n",
      "                  32      2    1          fwd    torch.bfloat16  22.664595\n",
      "                               2          fwd    torch.bfloat16  22.856705\n",
      "                  16      4    2          fwd    torch.bfloat16  23.787737\n",
      "                               1          fwd    torch.bfloat16  24.844409\n",
      "                                                                 cuda_time\n",
      "n    h d  block_j block_k warp num_stages method dtype                    \n",
      "1024 8 32 64      32      4    2          fwd    torch.bfloat16  26.560928\n",
      "          128     32      4    1          fwd    torch.bfloat16  27.156481\n",
      "          64      32      4    1          fwd    torch.bfloat16  28.299059\n",
      "                  16      2    2          fwd    torch.bfloat16  28.648557\n",
      "                               3          fwd    torch.bfloat16  28.667065\n",
      "                                                                 cuda_time\n",
      "n    h d  block_j block_k warp num_stages method dtype                    \n",
      "1024 8 64 128     32      8    2          fwd    torch.bfloat16  49.542606\n",
      "                  64      4    2          fwd    torch.bfloat16  50.072575\n",
      "          64      16      4    2          fwd    torch.bfloat16  50.135787\n",
      "                               3          fwd    torch.bfloat16  50.235394\n",
      "                          2    2          fwd    torch.bfloat16  51.690170\n"
     ]
    }
   ],
   "source": [
    "for m_name, m_df in mean_df.groupby([\"method\"]):\n",
    "    print(m_name)\n",
    "    for n_, n_df in m_df.groupby([\"n\"]):\n",
    "        print(n_)\n",
    "        for n, f in n_df.groupby([\"h\", \"d\"]):\n",
    "            print(f.sort_values(\"cuda_time\")[[\"cuda_time\"]].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'block_j': 64, 'block_k': 128, 'warp': 8, 'num_stages': 4}"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lu = FastParameterLookup(create_parameter_grid(df[df[\"method\"] == \"fwd\"]))\n",
    "\n",
    "lu.get_parameters(64, 1, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'block_j': 32, 'block_k': 128, 'warp': 2, 'num_stages': 4}"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import yaml\n",
    "from typing import Dict\n",
    "\n",
    "\n",
    "def create_config_lookup(df: pd.DataFrame) -> str:\n",
    "    \"\"\"Create grid configuration from DataFrame.\"\"\"\n",
    "    # Get mean cuda_time for each configuration\n",
    "    mean_times = (\n",
    "        df.groupby([\"n\", \"h\", \"d\", \"block_j\", \"block_k\", \"warp\", \"num_stages\"])[\n",
    "            \"cuda_time\"\n",
    "        ]\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # For each n,h,d combo, find the row with minimum cuda_time\n",
    "    best_params = mean_times.loc[\n",
    "        mean_times.groupby([\"n\", \"h\", \"d\"])[\"cuda_time\"].idxmin()\n",
    "    ]\n",
    "\n",
    "    grid = {\n",
    "        \"grid_points\": {\n",
    "            \"n\": sorted(df[\"n\"].unique().tolist()),\n",
    "            \"h\": sorted(df[\"h\"].unique().tolist()),\n",
    "            \"d\": sorted(df[\"d\"].unique().tolist()),\n",
    "        },\n",
    "        \"settings\": {},\n",
    "    }\n",
    "\n",
    "    # Store best parameters for each n,h,d point\n",
    "    for _, row in best_params.iterrows():\n",
    "        grid[\"settings\"][f\"{int(row['n'])},{int(row['h'])},{int(row['d'])}\"] = {\n",
    "            \"block_j\": int(row[\"block_j\"]),\n",
    "            \"block_k\": int(row[\"block_k\"]),\n",
    "            \"warp\": int(row[\"warp\"]),\n",
    "            \"num_stages\": int(row[\"num_stages\"]),\n",
    "        }\n",
    "\n",
    "    return yaml.dump(grid, sort_keys=False, indent=2)\n",
    "\n",
    "\n",
    "cfg = create_parameter_grid(df[df[\"method\"] == \"fwd\"])\n",
    "lu = FastParameterLookup(cfg)\n",
    "lu.get_parameters(64, 8, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fwd_yaml = create_config_lookup(df[df[\"method\"] == \"fwd\"])\n",
    "\n",
    "with open(cfg_dir / \"fwd.yaml\", \"w\") as f:\n",
    "    f.write(fwd_yaml)\n",
    "\n",
    "bwd_dq_yaml = create_config_lookup(df[df[\"method\"] == \"bwd_dq\"])\n",
    "with open(cfg_dir / \"bwd_dq.yaml\", \"w\") as f:\n",
    "    f.write(bwd_dq_yaml)\n",
    "\n",
    "bwd_dkvb_yaml = create_config_lookup(df[df[\"method\"] == \"bwd_dkvb\"])\n",
    "with open(cfg_dir / \"bwd_dkvb.yaml\", \"w\") as f:\n",
    "    f.write(bwd_dkvb_yaml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid_points:\n",
      "  n:\n",
      "  - 32\n",
      "  - 64\n",
      "  - 128\n",
      "  - 256\n",
      "  - 512\n",
      "  - 1024\n",
      "  h:\n",
      "  - 1\n",
      "  - 2\n",
      "  - 4\n",
      "  - 8\n",
      "  d:\n",
      "  - 32\n",
      "  - 64\n",
      "settings:\n",
      "  32,1,32:\n",
      "    block_j: 64\n",
      "    block_k: 64\n",
      "    warp: 8\n",
      "    num_stages: 2\n",
      "  32,1,64:\n",
      "    block_j: 32\n",
      "    block_k: 64\n",
      "    warp: 2\n",
      "    num_stages: 3\n",
      "  32,2,32:\n",
      "    block_j: 16\n",
      "    block_k: 128\n",
      "    warp: 1\n",
      "    num_stages: 2\n",
      "  32,2,64:\n",
      "    block_j: 32\n",
      "    block_k: 64\n",
      "    warp: 1\n",
      "    num_stages: 3\n",
      "  32,4,32:\n",
      "    block_j: 16\n",
      "    block_k: 64\n",
      "    warp: 1\n",
      "    num_stages: 4\n",
      "  32,4,64:\n",
      "    block_j: 16\n",
      "    block_k: 128\n",
      "    warp: 1\n",
      "    num_stages: 6\n",
      "  32,8,32:\n",
      "    block_j: 16\n",
      "    block_k: 16\n",
      "    warp: 1\n",
      "    num_stages: 3\n",
      "  32,8,64:\n",
      "    block_j: 128\n",
      "    block_k: 64\n",
      "    warp: 4\n",
      "    num_stages: 1\n",
      "  64,1,32:\n",
      "    block_j: 16\n",
      "    block_k: 16\n",
      "    warp: 2\n",
      "    num_stages: 6\n",
      "  64,1,64:\n",
      "    block_j: 16\n",
      "    block_k: 64\n",
      "    warp: 2\n",
      "    num_stages: 4\n",
      "  64,2,32:\n",
      "    block_j: 16\n",
      "    block_k: 16\n",
      "    warp: 8\n",
      "    num_stages: 2\n",
      "  64,2,64:\n",
      "    block_j: 16\n",
      "    block_k: 32\n",
      "    warp: 2\n",
      "    num_stages: 4\n",
      "  64,4,32:\n",
      "    block_j: 16\n",
      "    block_k: 32\n",
      "    warp: 1\n",
      "    num_stages: 6\n",
      "  64,4,64:\n",
      "    block_j: 64\n",
      "    block_k: 16\n",
      "    warp: 1\n",
      "    num_stages: 6\n",
      "  64,8,32:\n",
      "    block_j: 32\n",
      "    block_k: 128\n",
      "    warp: 2\n",
      "    num_stages: 4\n",
      "  64,8,64:\n",
      "    block_j: 16\n",
      "    block_k: 64\n",
      "    warp: 4\n",
      "    num_stages: 2\n",
      "  128,1,32:\n",
      "    block_j: 64\n",
      "    block_k: 16\n",
      "    warp: 1\n",
      "    num_stages: 3\n",
      "  128,1,64:\n",
      "    block_j: 64\n",
      "    block_k: 32\n",
      "    warp: 8\n",
      "    num_stages: 2\n",
      "  128,2,32:\n",
      "    block_j: 64\n",
      "    block_k: 128\n",
      "    warp: 8\n",
      "    num_stages: 4\n",
      "  128,2,64:\n",
      "    block_j: 128\n",
      "    block_k: 16\n",
      "    warp: 4\n",
      "    num_stages: 2\n",
      "  128,4,32:\n",
      "    block_j: 32\n",
      "    block_k: 32\n",
      "    warp: 2\n",
      "    num_stages: 2\n",
      "  128,4,64:\n",
      "    block_j: 64\n",
      "    block_k: 128\n",
      "    warp: 4\n",
      "    num_stages: 2\n",
      "  128,8,32:\n",
      "    block_j: 32\n",
      "    block_k: 128\n",
      "    warp: 2\n",
      "    num_stages: 3\n",
      "  128,8,64:\n",
      "    block_j: 64\n",
      "    block_k: 16\n",
      "    warp: 2\n",
      "    num_stages: 2\n",
      "  256,1,32:\n",
      "    block_j: 64\n",
      "    block_k: 16\n",
      "    warp: 2\n",
      "    num_stages: 3\n",
      "  256,1,64:\n",
      "    block_j: 128\n",
      "    block_k: 16\n",
      "    warp: 4\n",
      "    num_stages: 3\n",
      "  256,2,32:\n",
      "    block_j: 64\n",
      "    block_k: 16\n",
      "    warp: 4\n",
      "    num_stages: 2\n",
      "  256,2,64:\n",
      "    block_j: 64\n",
      "    block_k: 16\n",
      "    warp: 4\n",
      "    num_stages: 2\n",
      "  256,4,32:\n",
      "    block_j: 32\n",
      "    block_k: 32\n",
      "    warp: 2\n",
      "    num_stages: 1\n",
      "  256,4,64:\n",
      "    block_j: 128\n",
      "    block_k: 16\n",
      "    warp: 4\n",
      "    num_stages: 3\n",
      "  256,8,32:\n",
      "    block_j: 128\n",
      "    block_k: 32\n",
      "    warp: 8\n",
      "    num_stages: 1\n",
      "  256,8,64:\n",
      "    block_j: 64\n",
      "    block_k: 16\n",
      "    warp: 2\n",
      "    num_stages: 2\n",
      "  512,1,32:\n",
      "    block_j: 128\n",
      "    block_k: 64\n",
      "    warp: 8\n",
      "    num_stages: 1\n",
      "  512,1,64:\n",
      "    block_j: 64\n",
      "    block_k: 16\n",
      "    warp: 4\n",
      "    num_stages: 2\n",
      "  512,2,32:\n",
      "    block_j: 128\n",
      "    block_k: 32\n",
      "    warp: 4\n",
      "    num_stages: 1\n",
      "  512,2,64:\n",
      "    block_j: 64\n",
      "    block_k: 32\n",
      "    warp: 4\n",
      "    num_stages: 2\n",
      "  512,4,32:\n",
      "    block_j: 128\n",
      "    block_k: 32\n",
      "    warp: 4\n",
      "    num_stages: 2\n",
      "  512,4,64:\n",
      "    block_j: 64\n",
      "    block_k: 64\n",
      "    warp: 4\n",
      "    num_stages: 1\n",
      "  512,8,32:\n",
      "    block_j: 128\n",
      "    block_k: 32\n",
      "    warp: 4\n",
      "    num_stages: 1\n",
      "  512,8,64:\n",
      "    block_j: 128\n",
      "    block_k: 32\n",
      "    warp: 4\n",
      "    num_stages: 1\n",
      "  1024,1,32:\n",
      "    block_j: 64\n",
      "    block_k: 32\n",
      "    warp: 2\n",
      "    num_stages: 2\n",
      "  1024,1,64:\n",
      "    block_j: 64\n",
      "    block_k: 32\n",
      "    warp: 4\n",
      "    num_stages: 3\n",
      "  1024,2,32:\n",
      "    block_j: 128\n",
      "    block_k: 32\n",
      "    warp: 8\n",
      "    num_stages: 1\n",
      "  1024,2,64:\n",
      "    block_j: 64\n",
      "    block_k: 32\n",
      "    warp: 4\n",
      "    num_stages: 1\n",
      "  1024,4,32:\n",
      "    block_j: 64\n",
      "    block_k: 64\n",
      "    warp: 4\n",
      "    num_stages: 1\n",
      "  1024,4,64:\n",
      "    block_j: 64\n",
      "    block_k: 64\n",
      "    warp: 4\n",
      "    num_stages: 1\n",
      "  1024,8,32:\n",
      "    block_j: 64\n",
      "    block_k: 32\n",
      "    warp: 4\n",
      "    num_stages: 2\n",
      "  1024,8,64:\n",
      "    block_j: 128\n",
      "    block_k: 32\n",
      "    warp: 8\n",
      "    num_stages: 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "from bisect import bisect_right\n",
    "\n",
    "\n",
    "class FastParameterLookup:\n",
    "    def __init__(self, config_str: str):\n",
    "        config = yaml.safe_load(config_str)\n",
    "\n",
    "        # Create sorted lists of values for each dimension\n",
    "        self.n_vals = sorted(config[\"grid_points\"][\"n\"])\n",
    "        self.d_vals = sorted(config[\"grid_points\"][\"d\"])\n",
    "        self.h_vals = sorted(config[\"grid_points\"][\"h\"])\n",
    "\n",
    "        # Create nested lookup structure {n -> {d -> {h -> params}}}\n",
    "        # yeah this isn't exactly correct but whatevs\n",
    "        self.lookup = {}\n",
    "        for key, params in config[\"settings\"].items():\n",
    "            n, h, d = map(float, key.split(\",\"))\n",
    "            if n not in self.lookup:\n",
    "                self.lookup[n] = {}\n",
    "            if d not in self.lookup[n]:\n",
    "                self.lookup[n][d] = {}\n",
    "            self.lookup[n][d][h] = params\n",
    "\n",
    "    def get_parameters(self, n: float, h: float, d: float) -> Dict[str, int]:\n",
    "        i = bisect_right(self.n_vals, n)\n",
    "        n_closest = self.n_vals[i - 1] if i > 0 else self.n_vals[0]\n",
    "\n",
    "        i = bisect_right(self.d_vals, d)\n",
    "        d_closest = self.d_vals[i - 1] if i > 0 else self.d_vals[0]\n",
    "\n",
    "        i = bisect_right(self.h_vals, h)\n",
    "        h_closest = self.h_vals[i - 1] if i > 0 else self.h_vals[0]\n",
    "\n",
    "        return self.lookup[n_closest][d_closest][h_closest].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lu = FastParameterLookup(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "687 ns Â± 52.6 ns per loop (mean Â± std. dev. of 7 runs, 1,000,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit lu.get_parameters(64, 8, 32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
